# Social Sentiment Real-Time Tracker - ä½¿ç”¨æ–‡æ¡£

## æ¦‚è¿°

**Engine 2: Social Sentiment Real-Time Tracker** æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç¤¾äº¤åª’ä½“æƒ…ç»ªè¿½è¸ªå¼•æ“ï¼Œç”¨äºå®æ—¶ç›‘æ§Teslaç›¸å…³è®¨è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼Œè®¡ç®—OCIï¼ˆOwner Confidence Indexï¼Œè½¦ä¸»ä¿¡å¿ƒæŒ‡æ•°ï¼‰ï¼Œå¹¶æä¾›å†å²è¶‹åŠ¿åˆ†æã€‚

---

## æ ¸å¿ƒåŠŸèƒ½

1. **Reddit APIé›†æˆ** - æŠ“å–å¤šä¸ªå­ç‰ˆå—çš„å¸–å­å’Œè¯„è®º
2. **NLPæƒ…æ„Ÿåˆ†æ** - ä½¿ç”¨VADERè¿›è¡Œæƒ…æ„Ÿææ€§åˆ†æ
3. **OCIæŒ‡æ•°è®¡ç®—** - é‡åŒ–è½¦ä¸»/æŠ•èµ„è€…ä¿¡å¿ƒæ°´å¹³
4. **å†å²æ•°æ®å­˜å‚¨** - JSONå’ŒCSVåŒæ ¼å¼å­˜å‚¨
5. **å…³é”®è¯è¶‹åŠ¿åˆ†æ** - è¿½è¸ªç‰¹å®šè¯é¢˜çš„æƒ…æ„Ÿå˜åŒ–
6. **å­ç‰ˆå—å¯¹æ¯”åˆ†æ** - ä¸åŒç¤¾åŒºæƒ…ç»ªå·®å¼‚
7. **è‚¡ä»·ç›¸å…³æ€§å›æµ‹æ¡†æ¶** - ï¼ˆé¢„ç•™æ¥å£ï¼‰

---

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install praw vaderSentiment pandas numpy
```

**ä¾èµ–è¯´æ˜**ï¼š
- `praw` - Reddit APIå®˜æ–¹Pythonåº“
- `vaderSentiment` - ä¸“ä¸ºç¤¾äº¤åª’ä½“ä¼˜åŒ–çš„æƒ…æ„Ÿåˆ†æåº“
- `pandas` - æ•°æ®å¤„ç†
- `numpy` - æ•°å€¼è®¡ç®—

### 2. è·å–Reddit APIå¯†é’¥

#### æ­¥éª¤Aï¼šåˆ›å»ºRedditåº”ç”¨

1. è®¿é—® [https://www.reddit.com/prefs/apps](https://www.reddit.com/prefs/apps)
2. ç‚¹å‡» "create another app..." æˆ– "are you a developer? create an app..."
3. å¡«å†™è¡¨å•ï¼š
   - **name**: `TeslaSentimentTracker`ï¼ˆä»»æ„åç§°ï¼‰
   - **App type**: é€‰æ‹© `script`
   - **description**: `Sentiment analysis for investment research`
   - **about url**: ç•™ç©º
   - **redirect uri**: `http://localhost:8080`ï¼ˆå¿…å¡«ï¼Œä½†scriptç±»å‹ä¸ä¼šç”¨åˆ°ï¼‰
4. ç‚¹å‡» "create app"

#### æ­¥éª¤Bï¼šè·å–å¯†é’¥

åˆ›å»ºæˆåŠŸåï¼Œä½ ä¼šçœ‹åˆ°ï¼š
- **client_id**: åœ¨åº”ç”¨åç§°ä¸‹æ–¹ï¼ˆ14å­—ç¬¦çš„å­—ç¬¦ä¸²ï¼‰
- **client_secret**: æ ‡è®°ä¸º "secret" çš„å­—æ®µï¼ˆ27å­—ç¬¦çš„å­—ç¬¦ä¸²ï¼‰

ç¤ºä¾‹ï¼š
```
personal use script
abcdefghijklmn  <-- è¿™æ˜¯ä½ çš„ client_id

secret: xyzabcdefghijklmnopqrstuvwxyz123  <-- è¿™æ˜¯ä½ çš„ client_secret
```

#### æ­¥éª¤Cï¼šé…ç½®å¯†é’¥

ç¼–è¾‘ `config/sentiment_config.json`ï¼š

```json
{
  "reddit": {
    "client_id": "abcdefghijklmn",
    "client_secret": "xyzabcdefghijklmnopqrstuvwxyz123",
    "user_agent": "TeslaSentimentTracker/1.0 by YourRedditUsername"
  }
}
```

**é‡è¦**ï¼š
- å°† `YourRedditUsername` æ›¿æ¢ä¸ºä½ çš„Redditç”¨æˆ·å
- **åˆ‡å‹¿å…¬å¼€åˆ†äº«ä½ çš„å¯†é’¥**

### 3. è¿è¡Œåˆ†æ

```bash
cd /Users/milton/æŠ•èµ„å¤§å¸ˆ/IntelligenceEngine_v10/engines
python sentiment_tracker.py
```

---

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ç”¨æ³•

```python
from sentiment_tracker import SentimentTracker

# åˆå§‹åŒ–è¿½è¸ªå™¨
tracker = SentimentTracker(config_path='../config/sentiment_config.json')

# è¿è¡Œå®Œæ•´åˆ†æï¼ˆé»˜è®¤å‚æ•°ï¼šè¿‡å»ä¸€å‘¨ï¼Œæ¯ä¸ªå­ç‰ˆå—100ç¯‡å¸–å­ï¼‰
df, oci_metrics = tracker.run_full_analysis()

# æŸ¥çœ‹OCIåˆ†æ•°
print(f"å½“å‰OCIåˆ†æ•°: {oci_metrics['oci_score']}")
print(f"7å¤©ç§»åŠ¨å¹³å‡: {oci_metrics['oci_7d']}")
```

### è‡ªå®šä¹‰å‚æ•°

```python
# è‡ªå®šä¹‰æ—¶é—´èŒƒå›´å’ŒæŠ“å–æ•°é‡
df, oci_metrics = tracker.run_full_analysis(
    subreddits=['teslamotors', 'TeslaFSD'],  # æŒ‡å®šå­ç‰ˆå—
    time_filter='month',                      # è¿‡å»ä¸€ä¸ªæœˆï¼ˆday/week/month/yearï¼‰
    limit_per_sub=200                         # æ¯ä¸ªå­ç‰ˆå—200ç¯‡å¸–å­
)
```

### å•ç‹¬ä½¿ç”¨å„æ¨¡å—

```python
# 1. åªæŠ“å–æ•°æ®
posts = tracker.scrape_reddit('teslamotors', limit=50, time_filter='day')

# 2. åªåˆ†ææƒ…æ„Ÿ
sentiment = tracker.analyze_sentiment("FSD is amazing! Best feature ever.")
print(sentiment)  # {'neg': 0.0, 'neu': 0.409, 'pos': 0.591, 'compound': 0.8516}

# 3. å¤„ç†å·²æœ‰æ•°æ®
df = tracker.process_posts(posts)

# 4. è®¡ç®—OCI
oci_metrics = tracker.calculate_oci(df)

# 5. å…³é”®è¯åˆ†æ
keyword_trends = tracker.analyze_keyword_trends(df)
print(keyword_trends)
```

---

## è¾“å‡ºè¯´æ˜

### 1. OCIæŒ‡æ•°ï¼ˆOwner Confidence Indexï¼‰

**è®¡ç®—å…¬å¼**ï¼š
```
OCI = (æ­£é¢æåŠæ•° - è´Ÿé¢æåŠæ•°) / æ€»æåŠæ•° Ã— 100
```

**è§£è¯»æ ‡å‡†**ï¼š
- **+40 ä»¥ä¸Š** - æåº¦ä¹è§‚ï¼ˆStrong Bullishï¼‰
- **+20 ~ +40** - ä¹è§‚ï¼ˆBullishï¼‰
- **0 ~ +20** - è½»å¾®ä¹è§‚ï¼ˆSlightly Bullishï¼‰
- **-20 ~ 0** - è½»å¾®æ‚²è§‚ï¼ˆSlightly Bearishï¼‰
- **-40 ~ -20** - æ‚²è§‚ï¼ˆBearishï¼‰
- **-40 ä»¥ä¸‹** - æåº¦æ‚²è§‚ï¼ˆStrong Bearishï¼‰

**åŠ æƒOCI**ï¼š
```
åŠ æƒOCI = Î£(æƒ…æ„Ÿåˆ†æ•° Ã— log(1 + å¸–å­çƒ­åº¦)) / Î£å¸–å­çƒ­åº¦ Ã— 100
```
è€ƒè™‘äº†é«˜çƒ­åº¦å¸–å­çš„å½±å“åŠ›ã€‚

### 2. æ•°æ®æ–‡ä»¶

æ‰€æœ‰è¾“å‡ºä¿å­˜åœ¨ `data/sentiment/` ç›®å½•ï¼š

#### A. CSVæ–‡ä»¶ï¼ˆ`sentiment_YYYYMMDD_HHMMSS.csv`ï¼‰
åŒ…å«æ‰€æœ‰å¸–å­å’Œè¯„è®ºçš„è¯¦ç»†æ•°æ®ï¼š
- `post_id` - å¸–å­ID
- `subreddit` - å­ç‰ˆå—
- `created_utc` - åˆ›å»ºæ—¶é—´
- `title` - æ ‡é¢˜/è¯„è®ºå†…å®¹
- `score` - çƒ­åº¦åˆ†æ•°
- `compound_sentiment` - å¤åˆæƒ…æ„Ÿåˆ†æ•°ï¼ˆ-1åˆ°+1ï¼‰
- `sentiment_label` - æƒ…æ„Ÿæ ‡ç­¾ï¼ˆpositive/neutral/negativeï¼‰
- `has_keywords` - æ˜¯å¦åŒ…å«å…³é”®è¯
- `matched_keywords` - åŒ¹é…çš„å…³é”®è¯åˆ—è¡¨

#### B. JSONæ–‡ä»¶ï¼ˆ`sentiment_YYYYMMDD_HHMMSS.json`ï¼‰
ç»“æ„åŒ–æ•°æ®ï¼š
```json
{
  "timestamp": "20260125_143022",
  "oci_metrics": {
    "oci_score": 12.5,
    "weighted_oci": 15.3,
    "oci_7d": 10.8,
    "oci_30d": 8.2,
    "positive_ratio": 45.2,
    "negative_ratio": 32.7,
    "neutral_ratio": 22.1,
    "total_mentions": 856,
    "keyword_mentions": 432
  },
  "data_summary": {...},
  "records": [...]
}
```

#### C. åˆ†ææŠ¥å‘Šï¼ˆ`report_YYYYMMDD_HHMMSS.txt`ï¼‰
äººç±»å¯è¯»çš„æ–‡æœ¬æŠ¥å‘Šï¼ŒåŒ…å«ï¼š
- OCIæŒ‡æ•°å’Œè§£è¯»
- æƒ…æ„Ÿåˆ†å¸ƒ
- å­ç‰ˆå—å¯¹æ¯”
- å…³é”®è¯çƒ­åº¦Top 10

#### D. å­ç‰ˆå—åˆ†æï¼ˆ`subreddit_analysis_YYYYMMDD_HHMMSS.csv`ï¼‰
æ¯ä¸ªå­ç‰ˆå—çš„æ±‡æ€»ç»Ÿè®¡ã€‚

#### E. å…³é”®è¯åˆ†æï¼ˆ`keyword_analysis_YYYYMMDD_HHMMSS.csv`ï¼‰
æ¯ä¸ªå…³é”®è¯çš„æåŠæ¬¡æ•°å’Œæƒ…æ„Ÿè¶‹åŠ¿ã€‚

---

## å…³é”®è¯é…ç½®

é»˜è®¤è¿½è¸ªçš„å…³é”®è¯ï¼ˆåœ¨ `sentiment_config.json` ä¸­é…ç½®ï¼‰ï¼š

```json
"keywords": [
  "FSD",                # å…¨è‡ªåŠ¨é©¾é©¶
  "autopilot",          # è‡ªåŠ¨è¾…åŠ©é©¾é©¶
  "service",            # æœåŠ¡
  "delivery",           # äº¤ä»˜
  "quality",            # è´¨é‡
  "reliability",        # å¯é æ€§
  "customer service",   # å®¢æˆ·æœåŠ¡
  "build quality",      # åˆ¶é€ è´¨é‡
  "recall",             # å¬å›
  "battery",            # ç”µæ± 
  "range",              # ç»­èˆª
  "charging",           # å……ç”µ
  "supercharger"        # è¶…çº§å……ç”µç«™
]
```

**è‡ªå®šä¹‰å…³é”®è¯**ï¼š
ç¼–è¾‘é…ç½®æ–‡ä»¶æˆ–åœ¨ä»£ç ä¸­ä¿®æ”¹ `SentimentTracker.KEYWORDS`ã€‚

---

## é«˜çº§åŠŸèƒ½

### 1. å†å²è¶‹åŠ¿åˆ†æ

```python
import pandas as pd
import glob

# åŠ è½½æ‰€æœ‰å†å²CSVæ–‡ä»¶
data_dir = '../data/sentiment'
all_files = glob.glob(f'{data_dir}/sentiment_*.csv')

# åˆå¹¶æ•°æ®
df_list = [pd.read_csv(f) for f in all_files]
df_all = pd.concat(df_list, ignore_index=True)

# æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æ¯æ—¥OCI
df_all['date'] = pd.to_datetime(df_all['created_utc']).dt.date
daily_oci = df_all.groupby('date').apply(
    lambda x: ((x['sentiment_label'] == 'positive').sum() -
               (x['sentiment_label'] == 'negative').sum()) / len(x) * 100
)

print(daily_oci)
```

### 2. ä¸è‚¡ä»·ç›¸å…³æ€§åˆ†æï¼ˆç¤ºä¾‹æ¡†æ¶ï¼‰

```python
import yfinance as yf

# è·å–Teslaè‚¡ä»·
tsla = yf.download('TSLA', start='2026-01-01', end='2026-01-25')

# åˆå¹¶OCIæ•°æ®å’Œè‚¡ä»·æ•°æ®
# ï¼ˆéœ€è¦å°†OCIæ•°æ®æŒ‰æ—¥æœŸèšåˆï¼‰
merged_df = pd.merge(daily_oci, tsla['Close'], left_index=True, right_index=True)

# è®¡ç®—ç›¸å…³æ€§
correlation = merged_df['oci'].corr(merged_df['Close'])
print(f"OCIä¸è‚¡ä»·ç›¸å…³æ€§: {correlation:.3f}")
```

### 3. æƒ…ç»ªå¼‚åŠ¨æ£€æµ‹

```python
# æ£€æµ‹OCIå¼‚å¸¸æ³¢åŠ¨
def detect_anomalies(df, threshold=2):
    """æ£€æµ‹æƒ…æ„Ÿå¼‚åŠ¨ï¼ˆè¶…è¿‡2ä¸ªæ ‡å‡†å·®ï¼‰"""
    df['date'] = pd.to_datetime(df['created_utc']).dt.date
    daily_sentiment = df.groupby('date')['compound_sentiment'].mean()

    mean = daily_sentiment.mean()
    std = daily_sentiment.std()

    anomalies = daily_sentiment[abs(daily_sentiment - mean) > threshold * std]
    return anomalies

# è¿è¡Œæ£€æµ‹
anomalies = detect_anomalies(df)
print("æƒ…ç»ªå¼‚åŠ¨æ—¥æœŸï¼š")
print(anomalies)
```

---

## æ•°æ®è´¨é‡ä¿éšœ

### 1. APIé™æµå¤„ç†
- æ¯ä¸ªå­ç‰ˆå—æŠ“å–åè‡ªåŠ¨å»¶è¿Ÿ1ç§’
- é¿å…è§¦å‘Redditçš„é€Ÿç‡é™åˆ¶ï¼ˆ60æ¬¡/åˆ†é’Ÿï¼‰

### 2. é”™è¯¯å¤„ç†
- ç½‘ç»œå¼‚å¸¸è‡ªåŠ¨è·³è¿‡
- å·²åˆ é™¤å¸–å­/è¯„è®ºæ ‡è®°ä¸º `[deleted]`
- ç©ºæ–‡æœ¬è¿”å›ä¸­æ€§æƒ…æ„Ÿåˆ†æ•°

### 3. æ•°æ®éªŒè¯
- è‡ªåŠ¨è¿‡æ»¤æ— æ•ˆè®°å½•
- æ—¶é—´æˆ³æ ¼å¼æ ‡å‡†åŒ–
- æƒ…æ„Ÿåˆ†æ•°èŒƒå›´æ£€æŸ¥ï¼ˆ-1åˆ°+1ï¼‰

---

## å¸¸è§é—®é¢˜

### Q1: APIè¿”å›403é”™è¯¯
**åŸå› **ï¼šRedditå¯†é’¥é…ç½®é”™è¯¯æˆ–user_agentæ ¼å¼ä¸æ­£ç¡®ã€‚
**è§£å†³**ï¼š
1. ç¡®è®¤ `client_id` å’Œ `client_secret` æ­£ç¡®
2. ç¡®ä¿ `user_agent` åŒ…å«ä½ çš„Redditç”¨æˆ·å
3. æ£€æŸ¥Redditè´¦å·æ˜¯å¦è¢«é™åˆ¶

### Q2: æŠ“å–æ•°æ®ä¸ºç©º
**åŸå› **ï¼šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å¸–å­ï¼Œæˆ–å­ç‰ˆå—åç§°é”™è¯¯ã€‚
**è§£å†³**ï¼š
1. æ£€æŸ¥å­ç‰ˆå—åç§°æ‹¼å†™ï¼ˆä¸éœ€è¦å‰ç¼€ `r/`ï¼‰
2. æ‰©å¤§æ—¶é—´èŒƒå›´ï¼ˆ`time_filter='month'`ï¼‰
3. å¢åŠ æŠ“å–æ•°é‡ï¼ˆ`limit_per_sub=200`ï¼‰

### Q3: VADERæƒ…æ„Ÿåˆ†æä¸å‡†ç¡®
**è¯´æ˜**ï¼šVADERæ˜¯ä¸ºç¤¾äº¤åª’ä½“è®¾è®¡çš„å¯å‘å¼æ¨¡å‹ï¼Œå‡†ç¡®ç‡çº¦80%ã€‚
**æ”¹è¿›æ–¹å‘**ï¼š
- æ·»åŠ é¢†åŸŸç‰¹å®šè¯å…¸ï¼ˆå¦‚ "recall" â†’ è´Ÿé¢ï¼‰
- ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆBERTã€RoBERTaï¼‰
- äººå·¥æ ‡æ³¨æ ·æœ¬è¿›è¡Œå¾®è°ƒ

### Q4: OCIåˆ†æ•°æ³¢åŠ¨å¤§
**åŸå› **ï¼šæ ·æœ¬é‡ä¸è¶³æˆ–æ—¶é—´çª—å£å¤ªçŸ­ã€‚
**è§£å†³**ï¼š
1. å¢åŠ æŠ“å–æ•°é‡ï¼ˆ`limit_per_sub=200+`ï¼‰
2. ä½¿ç”¨30å¤©ç§»åŠ¨å¹³å‡å¹³æ»‘æ³¢åŠ¨
3. å¯¹çƒ­é—¨å¸–å­åŠ æƒï¼ˆä½¿ç”¨ `weighted_oci`ï¼‰

### Q5: å¦‚ä½•å¢åŠ æ›´å¤šæ•°æ®æºï¼Ÿ
**æ‰©å±•æ–¹å‘**ï¼š
- Twitter APIï¼ˆéœ€è¦ç”³è¯·ï¼‰
- StockTwits
- Seeking Alphaè¯„è®º
- YouTubeè¯„è®ºï¼ˆTeslaå®˜æ–¹é¢‘é“ï¼‰

å‚è€ƒæ‰©å±•ä»£ç æ¡†æ¶ï¼š
```python
class TwitterSentimentTracker(SentimentTracker):
    def scrape_twitter(self, query, limit):
        # å®ç°TwitteræŠ“å–é€»è¾‘
        pass
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶å‘æŠ“å–ï¼ˆå¤šçº¿ç¨‹ï¼‰

```python
from concurrent.futures import ThreadPoolExecutor

def parallel_scrape(tracker, subreddits, limit=100):
    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(tracker.scrape_reddit, sub, limit)
                   for sub in subreddits]
        results = [f.result() for f in futures]
    return [post for sublist in results for post in sublist]

# ä½¿ç”¨
all_posts = parallel_scrape(tracker, ['teslamotors', 'TeslaFSD', 'RealTesla'])
```

### 2. æ•°æ®ç¼“å­˜

```python
import pickle
from datetime import datetime, timedelta

def load_cached_data(cache_file, max_age_hours=1):
    """åŠ è½½ç¼“å­˜æ•°æ®ï¼ˆ1å°æ—¶å†…æœ‰æ•ˆï¼‰"""
    if not os.path.exists(cache_file):
        return None

    mod_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
    if datetime.now() - mod_time > timedelta(hours=max_age_hours):
        return None

    with open(cache_file, 'rb') as f:
        return pickle.load(f)
```

---

## ç¤ºä¾‹æ•°æ®

å¦‚æœæ²¡æœ‰Reddit APIå¯†é’¥ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•ï¼š

```python
# åˆ›å»ºç¤ºä¾‹æ•°æ®
sample_posts = [
    {
        'id': 'sample1',
        'subreddit': 'teslamotors',
        'title': 'FSD v12 is incredible! Smoothest drive ever',
        'selftext': 'Just completed a 200 mile trip with zero interventions.',
        'score': 450,
        'upvote_ratio': 0.95,
        'num_comments': 87,
        'created_utc': datetime.now() - timedelta(hours=2),
        'url': 'https://reddit.com/sample1',
        'author': 'tesla_fan',
        'comments': [
            {
                'id': 'c1',
                'body': 'Totally agree! Game changer for road trips',
                'score': 35,
                'created_utc': datetime.now() - timedelta(hours=1),
                'author': 'user2'
            }
        ]
    },
    # ... æ›´å¤šç¤ºä¾‹æ•°æ®
]

# å¤„ç†ç¤ºä¾‹æ•°æ®
df = tracker.process_posts(sample_posts)
oci = tracker.calculate_oci(df)
```

---

## è·¯çº¿å›¾

### v1.1ï¼ˆè®¡åˆ’ä¸­ï¼‰
- [ ] Twitter APIé›†æˆ
- [ ] æƒ…ç»ªæ—¶é—´åºåˆ—å¯è§†åŒ–ï¼ˆPlotlyå›¾è¡¨ï¼‰
- [ ] å®æ—¶è­¦æŠ¥ï¼ˆOCIçªç ´é˜ˆå€¼æ—¶å‘é€é€šçŸ¥ï¼‰

### v1.2ï¼ˆè®¡åˆ’ä¸­ï¼‰
- [ ] æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆBERTå¾®è°ƒï¼‰
- [ ] å¤šè¯­è¨€æ”¯æŒï¼ˆä¸­æ–‡ç¤¾äº¤åª’ä½“ï¼‰
- [ ] è‚¡ä»·ç›¸å…³æ€§è‡ªåŠ¨åŒ–å›æµ‹

### v2.0ï¼ˆè®¡åˆ’ä¸­ï¼‰
- [ ] Webä»ªè¡¨æ¿ï¼ˆFlask/Dashï¼‰
- [ ] æ•°æ®åº“å­˜å‚¨ï¼ˆPostgreSQLï¼‰
- [ ] å®šæ—¶ä»»åŠ¡è°ƒåº¦ï¼ˆæ¯å°æ—¶æ›´æ–°ï¼‰

---

## æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯ | ç”¨é€” |
|-----|------|-----|
| Reddit API | PRAW | æ•°æ®æŠ“å– |
| æƒ…æ„Ÿåˆ†æ | VADER | NLPæƒ…æ„Ÿåˆ†ç±» |
| æ•°æ®å¤„ç† | Pandas | æ•°æ®æ¸…æ´—å’Œèšåˆ |
| æ•°å€¼è®¡ç®— | NumPy | ç»Ÿè®¡è®¡ç®— |
| å­˜å‚¨æ ¼å¼ | JSON + CSV | ç»“æ„åŒ–å­˜å‚¨ |

---

## è®¸å¯ä¸å…è´£å£°æ˜

**è®¸å¯**ï¼šæœ¬å·¥å…·ä»…ä¾›ä¸ªäººæŠ•èµ„ç ”ç©¶ä½¿ç”¨ã€‚

**å…è´£å£°æ˜**ï¼š
1. æƒ…æ„Ÿåˆ†æç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
2. OCIæŒ‡æ•°ä¸èƒ½é¢„æµ‹è‚¡ä»·èµ°åŠ¿
3. ç¤¾äº¤åª’ä½“æƒ…ç»ªå¯èƒ½å­˜åœ¨æ“çºµå’Œåå·®
4. ä½¿ç”¨Reddit APIéœ€éµå®ˆå…¶æœåŠ¡æ¡æ¬¾

**Reddit APIä½¿ç”¨æ¡æ¬¾**ï¼š
- ä¸å¾—ç”¨äºåƒåœ¾é‚®ä»¶æˆ–è‡ªåŠ¨åŒ–å‘å¸–
- ä¸å¾—è¶…è¿‡é€Ÿç‡é™åˆ¶
- ä¸å¾—å‡ºå”®æ•°æ®
- è¯¦è§ï¼šhttps://www.redditinc.com/policies/data-api-terms

---

## è”ç³»ä¸æ”¯æŒ

**é—®é¢˜æŠ¥å‘Š**ï¼šåœ¨é¡¹ç›®GitHub Issuesä¸­æäº¤

**è´¡çŒ®æŒ‡å—**ï¼šæ¬¢è¿æäº¤Pull Request

**æ–‡æ¡£æ›´æ–°**ï¼š2026-01-25

---

## é™„å½•ï¼šVADERæƒ…æ„Ÿåˆ†æè¯´æ˜

**VADERï¼ˆValence Aware Dictionary and sEntiment Reasonerï¼‰**æ˜¯ä¸“ä¸ºç¤¾äº¤åª’ä½“æ–‡æœ¬è®¾è®¡çš„æƒ…æ„Ÿåˆ†æå·¥å…·ã€‚

### ä¼˜åŠ¿
1. **é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¼˜åŒ–** - ç†è§£ä¿šè¯­ã€è¡¨æƒ…ç¬¦å·ã€å¤§å†™å¼ºè°ƒ
2. **æ— éœ€è®­ç»ƒ** - åŸºäºè¯å…¸çš„å¯å‘å¼æ–¹æ³•
3. **é€Ÿåº¦å¿«** - å®æ—¶åˆ†æå¤§é‡æ–‡æœ¬

### è¾“å‡ºè§£é‡Š
```python
{
    'neg': 0.1,      # è´Ÿé¢æƒ…æ„Ÿæ¯”ä¾‹
    'neu': 0.5,      # ä¸­æ€§æƒ…æ„Ÿæ¯”ä¾‹
    'pos': 0.4,      # æ­£é¢æƒ…æ„Ÿæ¯”ä¾‹
    'compound': 0.6  # å¤åˆåˆ†æ•°ï¼ˆ-1åˆ°+1ï¼Œç»¼åˆåˆ¤æ–­ï¼‰
}
```

**Compoundåˆ†æ•°åˆ¤æ–­æ ‡å‡†**ï¼š
- `>= 0.05` - æ­£é¢
- `<= -0.05` - è´Ÿé¢
- `-0.05 ~ 0.05` - ä¸­æ€§

### ç¤ºä¾‹
```python
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

# æ­£é¢ç¤ºä¾‹
print(analyzer.polarity_scores("FSD is AMAZING!!! ğŸš€"))
# {'neg': 0.0, 'neu': 0.36, 'pos': 0.64, 'compound': 0.8268}

# è´Ÿé¢ç¤ºä¾‹
print(analyzer.polarity_scores("Service is terrible. Worst experience ever."))
# {'neg': 0.52, 'neu': 0.48, 'pos': 0.0, 'compound': -0.8074}

# ä¸­æ€§ç¤ºä¾‹
print(analyzer.polarity_scores("I received my car today."))
# {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}
```

---

**ç¥æ‚¨æŠ•èµ„ç ”ç©¶é¡ºåˆ©ï¼**
