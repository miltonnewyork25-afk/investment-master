# TeslaæŠ•èµ„æƒ…æŠ¥å¼•æ“ v10.0 - ç³»ç»Ÿæ¶æ„è®¾è®¡

## ğŸ—ï¸ æ€»ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·ç•Œé¢å±‚                             â”‚
â”‚  å‘½ä»¤è¡ŒCLI â”‚ Web Dashboard â”‚ APIæœåŠ¡ â”‚ Jupyter Notebook     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ä¸»æ§ç³»ç»Ÿ (main.py)                       â”‚
â”‚  â€¢ é…ç½®åŠ è½½           â€¢ ä»»åŠ¡è°ƒåº¦          â€¢ é”™è¯¯å¤„ç†         â”‚
â”‚  â€¢ å¼•æ“ç¼–æ’           â€¢ æ—¥å¿—ç®¡ç†          â€¢ æ€§èƒ½ç›‘æ§         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     6å¤§æ•°æ®å¼•æ“å±‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Engine 1    â”‚ Engine 2  â”‚ Engine 3  â”‚ Engine 4    â”‚ Eng 5+6 â”‚
â”‚ SEC Monitor â”‚ Sentiment â”‚ Supply Ch.â”‚ Options     â”‚ Comp &  â”‚
â”‚             â”‚ Tracker   â”‚ Intel     â”‚ Decoder     â”‚ Predictorâ”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚             â”‚           â”‚            â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚                    æ•°æ®å±‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ SQLite DB  â”‚ â”‚ Cache   â”‚ â”‚ Raw Data â”‚ â”‚ ML Models    â”‚  â”‚
â”‚  â”‚ (ç»“æ„åŒ–)   â”‚ â”‚ (Redis) â”‚ â”‚ (JSON)   â”‚ â”‚ (Pickle)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è‡ªåŠ¨åŒ–ç³»ç»Ÿå±‚                            â”‚
â”‚  â€¢ ä»»åŠ¡è°ƒåº¦å™¨      â€¢ æŠ¥å‘Šç”Ÿæˆå™¨      â€¢ å‘Šè­¦ç³»ç»Ÿ           â”‚
â”‚  â€¢ æ•°æ®éªŒè¯å™¨      â€¢ æ€§èƒ½ä¼˜åŒ–å™¨      â€¢ å¤‡ä»½æ¢å¤           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     å¤–éƒ¨æ•°æ®æº                              â”‚
â”‚  SEC EDGAR â”‚ Reddit â”‚ Yahoo Finance â”‚ ä¾›åº”å•†è´¢æŠ¥ â”‚ ...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ å¼•æ“è¯¦ç»†è®¾è®¡

### Engine 1: SEC Filing Monitor

**èŒè´£**: ç›‘æ§SECæ–‡ä»¶ï¼ŒæŠ“å–å†…éƒ¨äººäº¤æ˜“å’Œæœºæ„æŒä»“

**æ•°æ®æµ**:
```
SEC EDGAR RSS Feed
    â†“
è§£ææ–°æäº¤çš„Form 4/13F
    â†“
ä¸‹è½½XML/HTMLæ–‡ä»¶
    â†“
æå–ç»“æ„åŒ–æ•°æ®
    â†“
å­˜å…¥database.insider_tradingè¡¨
    â†“
è§¦å‘å‘Šè­¦ï¼ˆå¦‚å¤§é¢äº¤æ˜“ï¼‰
```

**æ ¸å¿ƒç®—æ³•**:
```python
def detect_significant_trading(transactions):
    """æ£€æµ‹é‡å¤§äº¤æ˜“"""
    for tx in transactions:
        if abs(tx.value) > 10_000_000:  # $10Mé˜ˆå€¼
            return {
                'alert': True,
                'insider': tx.insider,
                'value': tx.value,
                'interpretation': interpret_motivation(tx)
            }
```

**æ•°æ®è¡¨ç»“æ„**:
```sql
CREATE TABLE insider_trading (
    id INTEGER PRIMARY KEY,
    filing_date DATE,
    transaction_date DATE,
    insider_name VARCHAR(255),
    insider_title VARCHAR(100),
    transaction_type VARCHAR(10),  -- BUY/SELL
    shares INTEGER,
    price_per_share FLOAT,
    total_value FLOAT,
    remaining_shares INTEGER,
    sec_file_url VARCHAR(500),
    created_at TIMESTAMP
);

CREATE INDEX idx_filing_date ON insider_trading(filing_date);
CREATE INDEX idx_insider_name ON insider_trading(insider_name);
```

---

### Engine 2: Social Sentiment Tracker

**èŒè´£**: å®æ—¶è¿½è¸ªReddit/Twitteræƒ…ç»ªï¼Œè®¡ç®—OCIæŒ‡æ•°

**æ•°æ®æµ**:
```
Reddit API (PRAW)
    â†“
æŠ“å–çƒ­é—¨å¸–å­ï¼ˆr/teslamotors, r/TeslaFSD, r/RealTeslaï¼‰
    â†“
è¿‡æ»¤ç›¸å…³å¸–å­ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
    â†“
NLPæƒ…æ„Ÿåˆ†æï¼ˆVADERï¼‰
    â†“
è®¡ç®—OCIæŒ‡æ•°ï¼ˆ-100 to +100ï¼‰
    â†“
å­˜å…¥database.sentiment_historyè¡¨
    â†“
ä¸è‚¡ä»·ç›¸å…³æ€§åˆ†æ
```

**OCIè®¡ç®—å…¬å¼**:
```python
def calculate_OCI(posts):
    """
    OCI (Owner Confidence Index) = åŠ æƒæƒ…æ„Ÿåˆ†æ•°
    æƒé‡å› å­ï¼šupvotesã€commentsã€ä½œè€…karma
    """
    weighted_scores = []

    for post in posts:
        # åŸºç¡€æƒ…æ„Ÿåˆ†æ•°ï¼ˆ-1 to +1ï¼‰
        sentiment = VADER(post.title + post.text).compound

        # æƒé‡è®¡ç®—
        engagement_weight = log(post.upvotes + 1) * log(post.comments + 1)
        credibility_weight = min(log(post.author_karma + 1), 5)

        # åŠ æƒåˆ†æ•°
        weighted_score = sentiment * engagement_weight * credibility_weight
        weighted_scores.append(weighted_score)

    # å½’ä¸€åŒ–åˆ°-100è‡³+100
    OCI = (sum(weighted_scores) / len(weighted_scores)) * 100
    return round(OCI, 2)
```

**å†å²å›æµ‹éªŒè¯**:
```python
def backtest_OCI_vs_stock_price(start_date, end_date):
    """
    å›æµ‹OCIä¸è‚¡ä»·ç›¸å…³æ€§
    è¿”å›ï¼šç›¸å…³ç³»æ•°ã€é¢†å…ˆæ»åå…³ç³»ã€èƒœç‡
    """
    oci_data = get_oci_history(start_date, end_date)
    price_data = get_stock_price(start_date, end_date)

    # è®¡ç®—ç›¸å…³ç³»æ•°ï¼ˆæ»å0-30å¤©ï¼‰
    correlations = []
    for lag in range(31):
        corr = pearson_correlation(
            oci_data,
            price_data.shift(lag)
        )
        correlations.append({'lag': lag, 'corr': corr})

    best_lag = max(correlations, key=lambda x: abs(x['corr']))

    # è®¡ç®—äº¤æ˜“ä¿¡å·èƒœç‡
    signals = generate_trading_signals(oci_data, threshold=20)
    wins, total = evaluate_signals(signals, price_data)
    win_rate = wins / total

    return {
        'best_lag_days': best_lag['lag'],
        'correlation': best_lag['corr'],
        'win_rate': win_rate,
        'total_signals': total
    }
```

---

### Engine 3: Supply Chain Intelligence

**èŒè´£**: ç›‘æ§ä¾›åº”å•†è´¢æŠ¥ï¼Œæ¨æ–­å¯¹Teslaå½±å“

**æ•°æ®æµ**:
```
ä¾›åº”å•†åˆ—è¡¨ï¼ˆCATL, TSMC, IDRAç­‰ï¼‰
    â†“
å®šæœŸä¸‹è½½è´¢æŠ¥PDF/HTML
    â†“
NLPæå–å…³é”®æ•°æ®
    â†“
æ¨æ–­Teslaè®¢å•å˜åŒ–
    â†“
ç”Ÿæˆäº¤æ˜“ä¿¡å·
    â†“
å­˜å…¥database.supply_chain_signalsè¡¨
```

**æ¨æ–­é€»è¾‘**:
```python
def infer_tesla_impact(supplier_data, supplier_config):
    """
    ä»ä¾›åº”å•†æ•°æ®æ¨æ–­Teslaå½±å“
    """
    # 1. æå–ç›¸å…³æ•°æ®
    overseas_revenue = extract_keyword(
        supplier_data,
        keywords=['overseas', 'North America', 'æµ·å¤–', 'åŒ—ç¾']
    )
    auto_segment = extract_keyword(
        supplier_data,
        keywords=['automotive', 'EV', 'æ±½è½¦', 'ç”µåŠ¨è½¦']
    )

    # 2. è®¡ç®—å¢é€Ÿ
    yoy_growth = (overseas_revenue / last_year_revenue) - 1

    # 3. ä¼°ç®—Teslaå æ¯”ï¼ˆåŸºäºå†å²æ¨¡å¼ï¼‰
    tesla_share = estimate_tesla_share(
        supplier=supplier_config.name,
        segment=supplier_config.segment,
        market='US'
    )

    # 4. æ¨æ–­Teslaè®¢å•å˜åŒ–
    tesla_order_change = yoy_growth * tesla_share

    # 5. ç”Ÿæˆä¿¡å·
    if tesla_order_change > 0.30:  # +30%
        signal = {
            'type': 'BULLISH',
            'strength': min(tesla_order_change * 10, 10),
            'confidence': calculate_confidence(supplier_data),
            'rationale': f'{supplier_config.name} {supplier_config.segment} segment +{tesla_order_change:.0%} YoY implies strong Tesla demand'
        }

    return signal
```

**ä¾›åº”å•†é…ç½®ç¤ºä¾‹**:
```yaml
# suppliers_config.yaml
suppliers:
  - name: CATL
    ticker: 300750.SZ
    exchange: SZSE
    segment: battery
    ir_url: http://www.catl.com/ir/
    tesla_revenue_share: 0.10  # Teslaå å…¶æ”¶å…¥10%
    earnings_schedule: quarterly
    key_metrics:
      - overseas_energy_storage_revenue
      - gross_margin
      - capacity_utilization

  - name: TSMC
    ticker: 2330.TW
    exchange: TWSE
    segment: chip
    ir_url: https://investor.tsmc.com/
    tesla_revenue_share: 0.02
    key_metrics:
      - automotive_revenue
      - N5_N7_advanced_node_revenue
      - capacity_booked_percentage
```

---

### Engine 4: Options Market Decoder

**èŒè´£**: è§£ç æœŸæƒå¸‚åœºï¼Œè¯†åˆ«å¼‚å¸¸äº¤æ˜“å’Œéšå«æ¦‚ç‡

**æ•°æ®æµ**:
```
æœŸæƒé“¾æ•°æ®ï¼ˆå®æ—¶ï¼‰
    â†“
è®¡ç®—Put/Call Ratio
    â†“
è®¡ç®—éšå«æ³¢åŠ¨ç‡
    â†“
æ£€æµ‹å¼‚å¸¸äº¤æ˜“
    â†“
åæ¨å¸‚åœºéšå«æ¦‚ç‡
    â†“
å­˜å…¥database.options_signalsè¡¨
```

**å¼‚å¸¸äº¤æ˜“æ£€æµ‹ç®—æ³•**:
```python
def detect_unusual_options_activity(options_data):
    """
    æ£€æµ‹å¼‚å¸¸æœŸæƒæ´»åŠ¨ï¼ˆUnusual Options Activityï¼‰
    """
    unusual_trades = []

    for option in options_data:
        # æ¡ä»¶1ï¼šæˆäº¤é‡å¼‚å¸¸
        volume_anomaly = option.volume > (option.open_interest * 2)

        # æ¡ä»¶2ï¼šå•ç¬”å¤§å•
        large_trade = option.volume > 1000 and option.volume == option.volume_spike

        # æ¡ä»¶3ï¼šä»·æ ¼å¼‚å¸¸
        price_spike = (option.last_price / option.prev_close) > 1.5

        # æ¡ä»¶4ï¼šéšå«æ³¢åŠ¨ç‡çªå˜
        iv_spike = (option.implied_volatility - option.historical_iv) > 0.20

        if any([volume_anomaly, large_trade, price_spike, iv_spike]):
            unusual_trades.append({
                'option': option,
                'alert_reasons': {
                    'volume': volume_anomaly,
                    'size': large_trade,
                    'price': price_spike,
                    'iv': iv_spike
                },
                'interpretation': interpret_unusual_trade(option)
            })

    return unusual_trades

def interpret_unusual_trade(option):
    """è§£é‡Šå¼‚å¸¸äº¤æ˜“å«ä¹‰"""
    if option.type == 'CALL' and option.strike > current_price * 1.1:
        return 'Bullish bet on significant upside (>10%)'
    elif option.type == 'PUT' and option.strike < current_price * 0.9:
        return 'Hedging downside risk or bearish bet'
    elif option.volume > 10000:
        return 'Institutional-sized position, possible informed trading'
    # ...æ›´å¤šè§„åˆ™
```

**éšå«æ¦‚ç‡å€’æ¨**:
```python
def reverse_engineer_market_probabilities(stock_price, options_chain):
    """
    ä»æœŸæƒä»·æ ¼åæ¨å¸‚åœºå¯¹å„åœºæ™¯çš„éšå«æ¦‚ç‡
    åŸºäºBlack-ScholesæœŸæƒå®šä»·æ¨¡å‹
    """
    # 1. å®šä¹‰åœºæ™¯
    scenarios = {
        'bull': {'price_target': stock_price * 1.30, 'prob': None},
        'base': {'price_target': stock_price * 1.05, 'prob': None},
        'bear': {'price_target': stock_price * 0.70, 'prob': None}
    }

    # 2. é€‰æ‹©å…³é”®æœŸæƒ
    bull_option = find_option(options_chain, strike=scenarios['bull']['price_target'])
    bear_option = find_option(options_chain, strike=scenarios['bear']['price_target'])

    # 3. ä½¿ç”¨Black-Scholesåæ¨éšå«æ¦‚ç‡
    # ç®€åŒ–ï¼šæœŸæƒä»·æ ¼ â‰ˆ æ¦‚ç‡ Ã— å†…åœ¨ä»·å€¼
    scenarios['bull']['prob'] = bull_option.price / (
        max(scenarios['bull']['price_target'] - stock_price, 0)
    )

    scenarios['bear']['prob'] = bear_option.price / (
        max(stock_price - scenarios['bear']['price_target'], 0)
    )

    scenarios['base']['prob'] = 1 - scenarios['bull']['prob'] - scenarios['bear']['prob']

    return scenarios
```

---

### Engine 5: Competitor Tracker

**èŒè´£**: è¿½è¸ªç«å“æ•°æ®ï¼Œè®¡ç®—å¸‚åœºä»½é¢å’ŒæŠ€æœ¯å·®è·

**æ•°æ®æµ**:
```
ç«å“åˆ—è¡¨ï¼ˆBYD, XPEV, NIO, RIVN, LCIDï¼‰
    â†“
æŠ“å–æœˆåº¦é”€é‡ï¼ˆå…¬å¸å…¬å‘Š/è¡Œä¸šåä¼šï¼‰
    â†“
æŠ“å–æŠ€æœ¯å‚æ•°ï¼ˆå®˜ç½‘/è¯„æµ‹ï¼‰
    â†“
è®¡ç®—å¸‚åœºä»½é¢
    â†“
è®¡ç®—æŠ€æœ¯å·®è·æŒ‡æ•°
    â†“
å­˜å…¥database.competitor_dataè¡¨
```

**æŠ€æœ¯å·®è·é‡åŒ–**:
```python
def calculate_tech_gap_index(tesla_specs, competitor_specs):
    """
    è®¡ç®—æŠ€æœ¯å·®è·æŒ‡æ•°ï¼ˆ0-100ï¼‰
    100 = Teslaå®Œå…¨é¢†å…ˆ
    0 = ç«å“å®Œå…¨é¢†å…ˆ
    """
    dimensions = {
        'range': 0.30,      # ç»­èˆªæƒé‡30%
        'charging': 0.25,   # å……ç”µé€Ÿåº¦25%
        'autonomous': 0.30, # è‡ªåŠ¨é©¾é©¶30%
        'performance': 0.10,# æ€§èƒ½10%
        'price': 0.05       # ä»·æ ¼5%
    }

    scores = {}

    # ç»­èˆªå¯¹æ¯”
    scores['range'] = (tesla_specs.range / competitor_specs.range) * 100

    # å……ç”µé€Ÿåº¦ï¼ˆ10%-80%æ—¶é—´ï¼Œè¶ŠçŸ­è¶Šå¥½ï¼‰
    scores['charging'] = (competitor_specs.charging_time / tesla_specs.charging_time) * 100

    # è‡ªåŠ¨é©¾é©¶ï¼ˆå¹²é¢„ç‡ï¼Œè¶Šä½è¶Šå¥½ï¼‰
    scores['autonomous'] = (competitor_specs.intervention_rate / tesla_specs.intervention_rate) * 100

    # åŠ æƒå¹³å‡
    tech_gap_index = sum(
        scores[dim] * weight
        for dim, weight in dimensions.items()
    )

    return min(max(tech_gap_index, 0), 100)
```

---

### Engine 6: Earnings Predictor

**èŒè´£**: æ•´åˆ5å¼•æ“ä¿¡å·ï¼Œé¢„æµ‹ä¸‹å­£åº¦è´¢æŠ¥

**æ•°æ®æµ**:
```
5ä¸ªå¼•æ“ä¿¡å·
    â†“
ç‰¹å¾å·¥ç¨‹
    â†“
æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆXGBoostï¼‰
    â†“
é¢„æµ‹EPSã€æ”¶å…¥ã€æ¯›åˆ©ç‡
    â†“
è®¡ç®—ç½®ä¿¡åŒºé—´
    â†“
å­˜å…¥database.earnings_predictionsè¡¨
```

**ç‰¹å¾å·¥ç¨‹**:
```python
def engineer_features(signals_dict, quarter):
    """
    å°†5å¼•æ“ä¿¡å·è½¬æ¢ä¸ºMLæ¨¡å‹ç‰¹å¾
    """
    features = {}

    # Engine 1: å†…éƒ¨äººäº¤æ˜“ç‰¹å¾
    features['insider_net_buy_value'] = sum(
        tx.value for tx in signals_dict['sec']
        if tx.transaction == 'BUY'
    ) - sum(
        tx.value for tx in signals_dict['sec']
        if tx.transaction == 'SELL'
    )
    features['insider_transaction_count'] = len(signals_dict['sec'])

    # Engine 2: æƒ…ç»ªç‰¹å¾
    features['oci_avg'] = mean([s.oci for s in signals_dict['sentiment']])
    features['oci_trend'] = linear_regression_slope(
        [s.oci for s in signals_dict['sentiment']]
    )

    # Engine 3: ä¾›åº”é“¾ç‰¹å¾
    features['supplier_signals_bullish'] = sum(
        1 for s in signals_dict['supply_chain']
        if s.type == 'BULLISH'
    )
    features['catl_energy_growth'] = get_specific_signal(
        signals_dict['supply_chain'],
        supplier='CATL',
        metric='energy_storage_growth'
    )

    # Engine 4: æœŸæƒç‰¹å¾
    features['put_call_ratio'] = signals_dict['options']['put_call_ratio']
    features['implied_volatility'] = signals_dict['options']['iv_avg']
    features['unusual_activity_count'] = len(signals_dict['options']['unusual'])

    # Engine 5: ç«å“ç‰¹å¾
    features['market_share_change'] = (
        signals_dict['competitor']['tesla_share'] -
        signals_dict['competitor']['tesla_share_last_quarter']
    )

    # å®è§‚ç‰¹å¾
    features['sp500_return'] = get_sp500_return(quarter)
    features['vix_avg'] = get_vix_avg(quarter)

    return features
```

**MLæ¨¡å‹è®­ç»ƒ**:
```python
def train_earnings_prediction_model(historical_data):
    """
    è®­ç»ƒXGBoostæ¨¡å‹é¢„æµ‹è´¢æŠ¥
    è®­ç»ƒæ•°æ®ï¼šè¿‡å»20ä¸ªå­£åº¦
    """
    from xgboost import XGBRegressor

    # å‡†å¤‡æ•°æ®
    X = [engineer_features(q.signals, q.quarter) for q in historical_data]
    y_eps = [q.actual_eps for q in historical_data]
    y_revenue = [q.actual_revenue for q in historical_data]
    y_margin = [q.actual_margin for q in historical_data]

    # è®­ç»ƒ3ä¸ªæ¨¡å‹
    model_eps = XGBRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.05
    ).fit(X, y_eps)

    model_revenue = XGBRegressor(...).fit(X, y_revenue)
    model_margin = XGBRegressor(...).fit(X, y_margin)

    # äº¤å‰éªŒè¯
    cv_scores = cross_val_score(model_eps, X, y_eps, cv=5)
    print(f'EPS Prediction RÂ²: {cv_scores.mean():.3f}')

    return {
        'eps': model_eps,
        'revenue': model_revenue,
        'margin': model_margin
    }

def predict_next_quarter(models, current_signals):
    """
    é¢„æµ‹ä¸‹å­£åº¦è´¢æŠ¥
    """
    features = engineer_features(current_signals, quarter='next')

    predictions = {
        'eps': models['eps'].predict([features])[0],
        'revenue': models['revenue'].predict([features])[0],
        'margin': models['margin'].predict([features])[0]
    }

    # ç½®ä¿¡åŒºé—´ï¼ˆbootstrapï¼‰
    confidence_intervals = bootstrap_confidence_interval(
        models, features, n_iterations=1000
    )

    return {
        **predictions,
        'confidence_intervals': confidence_intervals,
        'probability_beat_consensus': calculate_beat_probability(
            predictions, consensus_estimates
        )
    }
```

---

## ğŸ”„ è‡ªåŠ¨åŒ–ç³»ç»Ÿè®¾è®¡

### ä»»åŠ¡è°ƒåº¦å™¨

```python
from apscheduler.schedulers.background import BackgroundScheduler

class IntelligenceScheduler:
    def __init__(self, config):
        self.scheduler = BackgroundScheduler()
        self.engines = initialize_engines(config)

    def start(self):
        # Engine 1: æ¯å¤©18:00è¿è¡Œï¼ˆSECæäº¤é€šå¸¸åœ¨æ”¶ç›˜åï¼‰
        self.scheduler.add_job(
            self.engines['sec'].run,
            trigger='cron',
            hour=18,
            minute=0
        )

        # Engine 2: æ¯å¤©09:00è¿è¡Œï¼ˆæŠ“å–è¿‡å¤œRedditè®¨è®ºï¼‰
        self.scheduler.add_job(
            self.engines['sentiment'].run,
            trigger='cron',
            hour=9,
            minute=0
        )

        # Engine 3: æ¯å‘¨ä¸€09:00è¿è¡Œï¼ˆè´¢æŠ¥å­£æ¯å¤©ï¼‰
        self.scheduler.add_job(
            self.engines['supply_chain'].run,
            trigger='cron',
            day_of_week='mon',
            hour=9,
            minute=0
        )

        # Engine 4: æ¯å°æ—¶è¿è¡Œï¼ˆå®æ—¶æœŸæƒç›‘æ§ï¼‰
        self.scheduler.add_job(
            self.engines['options'].run,
            trigger='interval',
            hours=1
        )

        # æ¯æ—¥æŠ¥å‘Šç”Ÿæˆï¼šæ¯å¤©19:00
        self.scheduler.add_job(
            self.generate_daily_report,
            trigger='cron',
            hour=19,
            minute=0
        )

        self.scheduler.start()
```

---

## ğŸ“Š æ•°æ®åº“Schemaå®Œæ•´è®¾è®¡

```sql
-- insider_tradingè¡¨ï¼ˆå·²åœ¨Engine 1éƒ¨åˆ†å®šä¹‰ï¼‰

-- sentiment_historyè¡¨
CREATE TABLE sentiment_history (
    id INTEGER PRIMARY KEY,
    date DATE,
    subreddit VARCHAR(50),
    oci_score FLOAT,
    sample_size INTEGER,
    positive_ratio FLOAT,
    negative_ratio FLOAT,
    top_keywords TEXT,  -- JSON array
    created_at TIMESTAMP
);

-- supply_chain_signalsè¡¨
CREATE TABLE supply_chain_signals (
    id INTEGER PRIMARY KEY,
    date DATE,
    supplier_name VARCHAR(100),
    quarter VARCHAR(10),
    key_metric VARCHAR(50),
    value FLOAT,
    yoy_growth FLOAT,
    tesla_impact_estimate FLOAT,
    signal_type VARCHAR(20),  -- BULLISH/BEARISH/NEUTRAL
    signal_strength FLOAT,    -- 0-10
    confidence FLOAT,         -- 0-1
    rationale TEXT,
    created_at TIMESTAMP
);

-- options_signalsè¡¨
CREATE TABLE options_signals (
    id INTEGER PRIMARY KEY,
    date DATE,
    put_call_ratio FLOAT,
    implied_volatility_avg FLOAT,
    max_pain FLOAT,
    unusual_activity_count INTEGER,
    largest_unusual_trade TEXT,  -- JSON
    market_sentiment VARCHAR(20),
    created_at TIMESTAMP
);

-- competitor_dataè¡¨
CREATE TABLE competitor_data (
    id INTEGER PRIMARY KEY,
    month DATE,
    company VARCHAR(50),
    sales_volume INTEGER,
    market_share FLOAT,
    tech_gap_index FLOAT,
    price_competitiveness FLOAT,
    created_at TIMESTAMP
);

-- earnings_predictionsè¡¨
CREATE TABLE earnings_predictions (
    id INTEGER PRIMARY KEY,
    prediction_date DATE,
    quarter VARCHAR(10),
    predicted_eps FLOAT,
    predicted_revenue FLOAT,
    predicted_margin FLOAT,
    confidence_interval_lower FLOAT,
    confidence_interval_upper FLOAT,
    beat_probability FLOAT,
    feature_importance TEXT,  -- JSON
    created_at TIMESTAMP
);

-- daily_reportsè¡¨ï¼ˆå­˜å‚¨ç”Ÿæˆçš„æŠ¥å‘Šï¼‰
CREATE TABLE daily_reports (
    id INTEGER PRIMARY KEY,
    report_date DATE,
    ç»¼åˆè¯„åˆ† FLOAT,
    å»ºè®®ä»“ä½ VARCHAR(20),
    å…³é”®ä¿¡å· TEXT,  -- JSON array
    report_markdown TEXT,
    report_html TEXT,
    created_at TIMESTAMP
);
```

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### ç¼“å­˜æœºåˆ¶
```python
from functools import lru_cache
import redis

# å†…å­˜ç¼“å­˜ï¼ˆLRUï¼‰
@lru_cache(maxsize=128)
def get_stock_price(ticker, date):
    """ç¼“å­˜è‚¡ä»·æ•°æ®ï¼Œé¿å…é‡å¤APIè°ƒç”¨"""
    return api.fetch_price(ticker, date)

# Redisåˆ†å¸ƒå¼ç¼“å­˜
cache = redis.Redis(host='localhost', port=6379)

def get_options_chain_cached(ticker):
    key = f'options:{ticker}:{datetime.now().date()}'
    cached = cache.get(key)

    if cached:
        return json.loads(cached)

    fresh_data = api.fetch_options(ticker)
    cache.setex(key, 3600, json.dumps(fresh_data))  # 1å°æ—¶è¿‡æœŸ
    return fresh_data
```

### å¹¶è¡Œå¤„ç†
```python
from concurrent.futures import ThreadPoolExecutor

def run_all_engines_parallel(engines):
    """å¹¶è¡Œè¿è¡Œæ‰€æœ‰å¼•æ“ï¼Œå‡å°‘æ€»æ—¶é—´"""
    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = {
            executor.submit(engine.run): name
            for name, engine in engines.items()
        }

        results = {}
        for future in as_completed(futures):
            engine_name = futures[future]
            try:
                results[engine_name] = future.result()
            except Exception as e:
                logger.error(f'{engine_name} failed: {e}')
                results[engine_name] = None

        return results
```

---

## ğŸ“¡ APIè®¾è®¡ï¼ˆå¯é€‰æ¨¡å—ï¼‰

```python
from flask import Flask, jsonify

app = Flask(__name__)

@app.route('/api/v1/daily_report', methods=['GET'])
def get_daily_report():
    """è·å–æœ€æ–°æ¯æ—¥ç®€æŠ¥"""
    report = db.query('SELECT * FROM daily_reports ORDER BY report_date DESC LIMIT 1')
    return jsonify(report)

@app.route('/api/v1/signals/<engine_name>', methods=['GET'])
def get_engine_signals(engine_name):
    """è·å–ç‰¹å®šå¼•æ“çš„æœ€æ–°ä¿¡å·"""
    signals = db.query(f'SELECT * FROM {engine_name}_signals ORDER BY date DESC LIMIT 10')
    return jsonify(signals)

@app.route('/api/v1/predict/<quarter>', methods=['GET'])
def get_earnings_prediction(quarter):
    """è·å–è´¢æŠ¥é¢„æµ‹"""
    prediction = db.query(f"SELECT * FROM earnings_predictions WHERE quarter='{quarter}'")
    return jsonify(prediction)
```

---

**ç³»ç»Ÿå¤æ‚åº¦**ï¼šğŸ”´ğŸ”´ğŸ”´ğŸ”´âšª (4/5)
**å¯ç»´æŠ¤æ€§**ï¼šğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ (5/5)
**å¯æ‰©å±•æ€§**ï¼šğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ (5/5)

