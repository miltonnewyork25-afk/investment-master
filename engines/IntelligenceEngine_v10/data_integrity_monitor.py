#!/usr/bin/env python3
"""
æ•°æ®çœŸå®æ€§ç›‘æµ‹å·¥å…·
Data Integrity Monitor for Investment Research Reports

åŠŸèƒ½:
1. æ‰«æMarkdownæŠ¥å‘Šä¸­çš„æ•°å­—
2. æ£€æŸ¥æ•°æ®æ¥æºæ ‡æ³¨
3. éªŒè¯æ•°æ®æ ‡æ³¨ç¬¦å·(âœ…ğŸ“ŠğŸ¯âš ï¸âŒ)
4. ç”Ÿæˆæ•°æ®è´¨é‡è¯„åˆ†æŠ¥å‘Š
5. æ ‡è®°å¯ç–‘æ•°æ®

ä½¿ç”¨æ–¹æ³•:
python data_integrity_monitor.py <æŠ¥å‘Šæ–‡ä»¶è·¯å¾„>
python data_integrity_monitor.py --dir <ç›®å½•è·¯å¾„>  # æ‰¹é‡æ‰«æ
"""

import re
import sys
import os
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass
from datetime import datetime
import json


@dataclass
class DataPoint:
    """æ•°æ®ç‚¹å¯¹è±¡"""
    value: str  # æ•°æ®å€¼
    context: str  # ä¸Šä¸‹æ–‡ï¼ˆæ‰€åœ¨å¥å­ï¼‰
    line_number: int  # è¡Œå·
    data_type: str  # æ•°æ®ç±»å‹ï¼ˆæ•°å­—/ç™¾åˆ†æ¯”/é‡‘é¢ï¼‰
    has_source: bool  # æ˜¯å¦æœ‰æ¥æºæ ‡æ³¨
    label: str  # æ ‡æ³¨ç±»å‹(VERIFIED/ESTIMATED/SAMPLE/ç­‰)
    confidence: int  # ç½®ä¿¡åº¦(0-100)


@dataclass
class QualityReport:
    """æ•°æ®è´¨é‡æŠ¥å‘Š"""
    file_name: str
    total_data_points: int
    verified_count: int
    estimated_count: int
    sample_count: int
    unverified_count: int
    quality_score: float
    issues: List[str]
    recommendations: List[str]


class DataIntegrityMonitor:
    """æ•°æ®å®Œæ•´æ€§ç›‘æµ‹å™¨"""

    # æ•°æ®æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
    PATTERNS = {
        'percentage': r'\b\d+\.?\d*%',  # ç™¾åˆ†æ¯”: 18.7%, 100%
        'number_with_unit': r'\b\d+\.?\d*[KMBT](?:äº¿|ä¸‡|åƒ)?',  # å¸¦å•ä½æ•°å­—: 1.2B, 500ä¸‡
        'currency': r'\$\d+(?:,\d{3})*(?:\.\d+)?[KMBT]?',  # è´§å¸: $450, $1.2B
        'plain_number': r'\b\d{1,3}(?:,\d{3})+(?:\.\d+)?',  # æ™®é€šæ•°å­—: 1,234,567
        'decimal': r'\b\d+\.\d+(?!%)',  # å°æ•°: 18.7 (ä¸åŒ…æ‹¬ç™¾åˆ†æ¯”)
        'date': r'\b20\d{2}[-/]\d{1,2}[-/]\d{1,2}\b',  # æ—¥æœŸ: 2026-01-25
        'time': r'\b\d{1,2}:\d{2}(?::\d{2})?\s?(?:UTC|EST|PST)?\b',  # æ—¶é—´: 08:00 UTC
    }

    # æ ‡æ³¨ç¬¦å·
    LABELS = {
        'âœ…': 'VERIFIED',
        'ğŸ“Š': 'ESTIMATED',
        'ğŸ¯': 'MODELED',
        'âš ï¸': 'SAMPLE',
        'âŒ': 'UNVERIFIED'
    }

    # å¯ç–‘å…³é”®è¯ï¼ˆè¡¨æ˜æ•°æ®å¯èƒ½ä¸ºè™šæ„ï¼‰
    SUSPICIOUS_KEYWORDS = [
        'Engine 1', 'Engine 2', 'Engine 3', 'Engine 4', 'Engine 5', 'Engine 6',
        'å®æ—¶ç›‘æ§', 'real-time monitoring',
        'å¼‚å¸¸å¤§å•', 'unusual activity',
        'å†…éƒ¨æ¶ˆæ¯', 'inside information',
        'ç‹¬å®¶è·æ‚‰', 'exclusively learned'
    ]

    # éœ€è¦æ¥æºçš„å…³é”®æ•°æ®ç±»å‹
    REQUIRE_SOURCE = [
        'æ¯›åˆ©ç‡', 'äº¤ä»˜é‡', 'å¸‚å€¼', 'è¥æ”¶', 'åˆ©æ¶¦',
        'margin', 'delivery', 'revenue', 'profit', 'market cap'
    ]

    def __init__(self):
        self.data_points: List[DataPoint] = []
        self.issues: List[str] = []
        self.recommendations: List[str] = []

    def scan_file(self, file_path: str) -> QualityReport:
        """æ‰«æå•ä¸ªæ–‡ä»¶"""
        print(f"\n{'='*80}")
        print(f"æ‰«ææ–‡ä»¶: {file_path}")
        print(f"{'='*80}\n")

        self.data_points = []
        self.issues = []
        self.recommendations = []

        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # é€è¡Œæ‰«æ
        for i, line in enumerate(lines, 1):
            self._scan_line(line, i)

        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_report(file_path)
        return report

    def _scan_line(self, line: str, line_number: int):
        """æ‰«æå•è¡Œ"""
        # 1. æ£€æµ‹æ•°å­—
        for pattern_name, pattern in self.PATTERNS.items():
            matches = re.finditer(pattern, line)
            for match in matches:
                value = match.group()
                context = line.strip()

                # åˆ¤æ–­æ ‡æ³¨ç±»å‹
                label = self._detect_label(line)

                # åˆ¤æ–­æ˜¯å¦æœ‰æ¥æº
                has_source = self._has_source(line, context)

                # è®¡ç®—ç½®ä¿¡åº¦
                confidence = self._calculate_confidence(value, context, label, has_source)

                data_point = DataPoint(
                    value=value,
                    context=context,
                    line_number=line_number,
                    data_type=pattern_name,
                    has_source=has_source,
                    label=label,
                    confidence=confidence
                )

                self.data_points.append(data_point)

        # 2. æ£€æµ‹å¯ç–‘å…³é”®è¯
        for keyword in self.SUSPICIOUS_KEYWORDS:
            if keyword in line:
                self.issues.append(
                    f"âš ï¸ è¡Œ{line_number}: å‘ç°å¯ç–‘å…³é”®è¯ '{keyword}' - {line.strip()[:80]}"
                )

        # 3. æ£€æµ‹ç¼ºå°‘æ¥æºçš„å…³é”®æ•°æ®
        for keyword in self.REQUIRE_SOURCE:
            if keyword in line.lower() and not self._has_source(line, line):
                self.issues.append(
                    f"âŒ è¡Œ{line_number}: '{keyword}' æ•°æ®ç¼ºå°‘æ¥æºæ ‡æ³¨ - {line.strip()[:80]}"
                )

    def _detect_label(self, line: str) -> str:
        """æ£€æµ‹æ•°æ®æ ‡æ³¨ç±»å‹"""
        for emoji, label in self.LABELS.items():
            if emoji in line:
                return label

        # æ£€æµ‹æ–‡æœ¬æ ‡æ³¨
        if 'VERIFIED' in line or 'æ¥æº:' in line or 'Source:' in line:
            return 'VERIFIED'
        elif 'ESTIMATED' in line or 'ä¼°ç®—' in line or 'é¢„æµ‹' in line:
            return 'ESTIMATED'
        elif 'SAMPLE' in line or 'EXAMPLE' in line or 'ç¤ºä¾‹' in line or 'æ¼”ç¤º' in line:
            return 'SAMPLE'
        elif 'Engine' in line:
            return 'UNVERIFIED'

        return 'UNLABELED'

    def _has_source(self, line: str, context: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æœ‰æ¥æºæ ‡æ³¨"""
        source_indicators = [
            'æ¥æº:', 'Source:', 'æ•°æ®æº:', 'Data source:',
            '(æ¥è‡ª', '(from', 'æ ¹æ®', 'according to',
            'SEC', 'EDGAR', '10-K', '10-Q', 'è´¢æŠ¥', 'earnings',
            'Bloomberg', 'Reuters', 'Yahoo Finance',
            'IR.tesla.com', 'investor relations'
        ]

        for indicator in source_indicators:
            if indicator in line or indicator in context:
                return True

        return False

    def _calculate_confidence(self, value: str, context: str,
                             label: str, has_source: bool) -> int:
        """è®¡ç®—æ•°æ®ç½®ä¿¡åº¦(0-100)"""
        score = 50  # åŸºç¡€åˆ†

        # æ ‡æ³¨ç±»å‹åŠ åˆ†
        if label == 'VERIFIED':
            score += 30
        elif label == 'ESTIMATED':
            score += 10
        elif label == 'SAMPLE':
            score -= 20
        elif label == 'UNVERIFIED':
            score -= 40

        # æœ‰æ¥æºåŠ åˆ†
        if has_source:
            score += 20
        else:
            score -= 15

        # Engineç³»ç»Ÿæ•°æ®ä¸¥é‡æ‰£åˆ†
        if 'Engine' in context:
            score -= 50

        # è´¢æŠ¥æ•°æ®åŠ åˆ†
        if any(word in context for word in ['10-K', '10-Q', 'è´¢æŠ¥', 'earnings report']):
            score += 15

        # é™åˆ¶èŒƒå›´
        return max(0, min(100, score))

    def _generate_report(self, file_path: str) -> QualityReport:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        # ç»Ÿè®¡å„ç±»æ•°æ®
        verified = sum(1 for dp in self.data_points if dp.label == 'VERIFIED')
        estimated = sum(1 for dp in self.data_points if dp.label == 'ESTIMATED')
        sample = sum(1 for dp in self.data_points if dp.label == 'SAMPLE')
        unverified = sum(1 for dp in self.data_points
                        if dp.label in ['UNVERIFIED', 'UNLABELED'])

        total = len(self.data_points)

        # è®¡ç®—è´¨é‡åˆ†æ•°(0-100)
        if total == 0:
            quality_score = 0
        else:
            # åŠ æƒè®¡ç®—
            weighted_sum = (
                verified * 100 +
                estimated * 60 +
                sample * 20 +
                unverified * 0
            )
            quality_score = weighted_sum / total

        # ç”Ÿæˆå»ºè®®
        if quality_score < 40:
            self.recommendations.append("ğŸ”´ è´¨é‡è¯„åˆ†è¿‡ä½ï¼Œå»ºè®®å…¨é¢ä¿®è®¢æ•°æ®æ¥æº")
        elif quality_score < 60:
            self.recommendations.append("ğŸŸ¡ è´¨é‡è¯„åˆ†ä¸­ç­‰ï¼Œéœ€è¦è¡¥å……æ•°æ®æ¥æºæ ‡æ³¨")
        else:
            self.recommendations.append("ğŸŸ¢ è´¨é‡è¯„åˆ†è‰¯å¥½ï¼Œç»§ç»­ä¿æŒæ•°æ®é€æ˜åº¦")

        if unverified > total * 0.3:
            self.recommendations.append(
                f"âŒ æœªéªŒè¯æ•°æ®è¿‡å¤š({unverified}/{total} = {unverified/total*100:.1f}%)ï¼Œ"
                "å»ºè®®åˆ é™¤æˆ–æ ‡æ³¨ä¸º'ç¤ºä¾‹'"
            )

        if verified < total * 0.2:
            self.recommendations.append(
                f"âš ï¸ å¯éªŒè¯æ•°æ®è¿‡å°‘({verified}/{total} = {verified/total*100:.1f}%)ï¼Œ"
                "å»ºè®®å¢åŠ å®˜æ–¹æ•°æ®æ¥æº"
            )

        # æ£€æµ‹é«˜é£é™©æ•°æ®
        high_risk_data = [dp for dp in self.data_points if dp.confidence < 30]
        if high_risk_data:
            self.recommendations.append(
                f"ğŸ”´ å‘ç°{len(high_risk_data)}ä¸ªé«˜é£é™©æ•°æ®ç‚¹(ç½®ä¿¡åº¦<30%)ï¼Œ"
                "å»ºè®®é‡ç‚¹å®¡æŸ¥"
            )

        return QualityReport(
            file_name=os.path.basename(file_path),
            total_data_points=total,
            verified_count=verified,
            estimated_count=estimated,
            sample_count=sample,
            unverified_count=unverified,
            quality_score=quality_score,
            issues=self.issues,
            recommendations=self.recommendations
        )

    def print_report(self, report: QualityReport):
        """æ‰“å°æŠ¥å‘Š"""
        print(f"\n{'='*80}")
        print(f"æ•°æ®è´¨é‡æŠ¥å‘Š: {report.file_name}")
        print(f"{'='*80}\n")

        # æ•°æ®ç»Ÿè®¡
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡")
        print(f"  æ€»æ•°æ®ç‚¹: {report.total_data_points}")
        print(f"  âœ… å¯éªŒè¯: {report.verified_count} "
              f"({report.verified_count/report.total_data_points*100:.1f}%)")
        print(f"  ğŸ“Š ä¼°ç®—: {report.estimated_count} "
              f"({report.estimated_count/report.total_data_points*100:.1f}%)")
        print(f"  âš ï¸ ç¤ºä¾‹: {report.sample_count} "
              f"({report.sample_count/report.total_data_points*100:.1f}%)")
        print(f"  âŒ æœªéªŒè¯: {report.unverified_count} "
              f"({report.unverified_count/report.total_data_points*100:.1f}%)")

        # è´¨é‡è¯„åˆ†
        print(f"\nğŸ¯ è´¨é‡è¯„åˆ†: {report.quality_score:.1f}/100")
        if report.quality_score >= 80:
            rating = "ğŸŸ¢ ä¼˜ç§€"
        elif report.quality_score >= 60:
            rating = "ğŸŸ¡ è‰¯å¥½"
        elif report.quality_score >= 40:
            rating = "ğŸŸ  åŠæ ¼"
        else:
            rating = "ğŸ”´ ä¸åˆæ ¼"
        print(f"   è¯„çº§: {rating}")

        # ä¸»è¦é—®é¢˜
        if report.issues:
            print(f"\nâš ï¸ ä¸»è¦é—®é¢˜ ({len(report.issues)}ä¸ª)")
            for i, issue in enumerate(report.issues[:10], 1):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                print(f"  {i}. {issue}")
            if len(report.issues) > 10:
                print(f"  ... è¿˜æœ‰{len(report.issues)-10}ä¸ªé—®é¢˜ï¼ˆè§å®Œæ•´æŠ¥å‘Šï¼‰")

        # å»ºè®®
        if report.recommendations:
            print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®")
            for i, rec in enumerate(report.recommendations, 1):
                print(f"  {i}. {rec}")

        # ä½ç½®ä¿¡åº¦æ•°æ®ç¤ºä¾‹
        low_confidence = sorted(
            [dp for dp in self.data_points if dp.confidence < 40],
            key=lambda x: x.confidence
        )
        if low_confidence:
            print(f"\nğŸ”´ ä½ç½®ä¿¡åº¦æ•°æ®ç¤ºä¾‹ (ç½®ä¿¡åº¦<40%)")
            for i, dp in enumerate(low_confidence[:5], 1):
                print(f"  {i}. è¡Œ{dp.line_number} [{dp.label}] "
                      f"ç½®ä¿¡åº¦{dp.confidence}% - {dp.context[:80]}")

        print(f"\n{'='*80}\n")

    def export_json(self, report: QualityReport, output_path: str):
        """å¯¼å‡ºJSONæŠ¥å‘Š"""
        data = {
            'file_name': report.file_name,
            'scan_time': datetime.now().isoformat(),
            'summary': {
                'total_data_points': report.total_data_points,
                'verified_count': report.verified_count,
                'estimated_count': report.estimated_count,
                'sample_count': report.sample_count,
                'unverified_count': report.unverified_count,
                'quality_score': round(report.quality_score, 2)
            },
            'data_points': [
                {
                    'line': dp.line_number,
                    'value': dp.value,
                    'type': dp.data_type,
                    'label': dp.label,
                    'has_source': dp.has_source,
                    'confidence': dp.confidence,
                    'context': dp.context[:100]
                }
                for dp in self.data_points
            ],
            'issues': report.issues,
            'recommendations': report.recommendations
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ… JSONæŠ¥å‘Šå·²å¯¼å‡º: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python data_integrity_monitor.py <æ–‡ä»¶è·¯å¾„>")
        print("  python data_integrity_monitor.py --dir <ç›®å½•è·¯å¾„>")
        print("\nç¤ºä¾‹:")
        print("  python data_integrity_monitor.py Teslaæ·±åº¦è°ƒç ”æŠ¥å‘Š_v10.0_èµšé’±æœºä¼šç‰ˆ.md")
        print("  python data_integrity_monitor.py --dir ./IntelligenceEngine_v10")
        sys.exit(1)

    monitor = DataIntegrityMonitor()

    # ç›®å½•æ‰«ææ¨¡å¼
    if sys.argv[1] == '--dir':
        if len(sys.argv) < 3:
            print("âŒ é”™è¯¯: è¯·æŒ‡å®šç›®å½•è·¯å¾„")
            sys.exit(1)

        dir_path = sys.argv[2]
        md_files = list(Path(dir_path).glob('*.md'))

        if not md_files:
            print(f"âŒ é”™è¯¯: ç›®å½• {dir_path} ä¸­æ²¡æœ‰æ‰¾åˆ°Markdownæ–‡ä»¶")
            sys.exit(1)

        print(f"ğŸ“ å‘ç° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")

        all_reports = []
        for md_file in md_files:
            report = monitor.scan_file(str(md_file))
            monitor.print_report(report)
            all_reports.append(report)

            # å¯¼å‡ºå•ä¸ªæ–‡ä»¶çš„JSONæŠ¥å‘Š
            json_path = str(md_file).replace('.md', '_quality_report.json')
            monitor.export_json(report, json_path)

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        print(f"\n{'='*80}")
        print("ğŸ“Š æ±‡æ€»æŠ¥å‘Š")
        print(f"{'='*80}\n")

        avg_score = sum(r.quality_score for r in all_reports) / len(all_reports)
        total_verified = sum(r.verified_count for r in all_reports)
        total_points = sum(r.total_data_points for r in all_reports)

        print(f"æ€»æ–‡ä»¶æ•°: {len(all_reports)}")
        print(f"å¹³å‡è´¨é‡åˆ†: {avg_score:.1f}/100")
        print(f"æ€»æ•°æ®ç‚¹: {total_points}")
        print(f"å¯éªŒè¯æ•°æ®: {total_verified} ({total_verified/total_points*100:.1f}%)")

        if avg_score < 50:
            print("\nğŸ”´ è­¦å‘Š: æ•´ä½“æ•°æ®è´¨é‡ä¸åˆæ ¼ï¼Œå»ºè®®å…¨é¢å®¡è®¡ä¿®æ­£")
        elif avg_score < 70:
            print("\nğŸŸ¡ æç¤º: æ•´ä½“æ•°æ®è´¨é‡ä¸­ç­‰ï¼Œå»ºè®®è¡¥å……æ¥æºæ ‡æ³¨")
        else:
            print("\nğŸŸ¢ è‰¯å¥½: æ•´ä½“æ•°æ®è´¨é‡è¾¾æ ‡")

    # å•æ–‡ä»¶æ‰«ææ¨¡å¼
    else:
        file_path = sys.argv[1]

        if not os.path.exists(file_path):
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
            sys.exit(1)

        report = monitor.scan_file(file_path)
        monitor.print_report(report)

        # å¯¼å‡ºJSONæŠ¥å‘Š
        json_path = file_path.replace('.md', '_quality_report.json')
        monitor.export_json(report, json_path)


if __name__ == '__main__':
    main()
