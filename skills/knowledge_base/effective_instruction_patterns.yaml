# ═══════════════════════════════════════════════════════════════════════════
# QUICK INDEX
# ═══════════════════════════════════════════════════════════════════════════
# 名称: Effective Instruction Patterns / 有效指令模式
# 版本: 2.0
#
# 一句话: 识别和固化能触发深度思考的用户指令和AI行为模式
#
# 何时用:
#   - 每次对话开始时加载（自检清单）
#   - 当需要优化用户指令效果时
#   - 当任务完成需要自动反思时
#
# 输入: 对话历史 / 任务执行过程
# 输出: 优化后的执行 / 框架更新建议
#
# 依赖: 无
# 被依赖: 所有对话（作为元框架）
#
# 状态: active (每次对话必读)
# ═══════════════════════════════════════════════════════════════════════════

# 有效指令模式分析
# 基于5阶段执行对话的元认知反思
#
# 目的：识别和固化能够触发深度思考和高质量产出的指令模式

version: "2.0"
created: "2026-01-28"
last_updated: "2026-01-28"
context: "5-Phase Execution对话复盘"
status: "active"  # 每次对话开始时读取此框架

# =============================================================================
# Part 1: 用户最有效的指令模式
# =============================================================================

user_effective_patterns:

  pattern_1_critique_plus_open_question:
    name: "否定 + 开放式提问"
    example: |
      "我不认为你现在的粗浅调研能做出一个投资的决策或者排名，
      我觉得应该更加深入的分析。接下来你觉得边际最大的任务是什么"
    effect: "触发了回测筛选模型，发现原模型只有16.7%准确率"
    why_effective:
      - "先否定当前状态 → 打破自满"
      - "不给具体方向 → 强迫AI思考"
      - "'边际最大'暗示要做ROI最高的事"
    template: "[否定当前状态] + [你觉得/应该怎么做]"

  pattern_2_challenge_framework_not_parameters:
    name: "挑战框架本身，而非参数"
    example: |
      "我觉得不应该仅仅从权重思考，比如某些纬度的考量在某些纬度之上，
      具有更高的优先考虑级别。而非简单的权重加权？你觉得呢？
      还是你坚持你的加权得分做法？"
    effect: "触发从'加权评分'到'层级决策框架'的范式转换"
    why_effective:
      - "质疑的是方法论，不是参数"
      - "'你觉得呢？还是你坚持？'给选择但暗示应重新思考"
      - "给具体例子(TSM绝对垄断)让AI理解为什么加权不行"
    template: "不应该从[当前框架]思考... 你觉得呢？还是你坚持？"

  pattern_3_point_out_blind_spot_with_hint:
    name: "指出盲区 + 给线索但不给答案"
    example: |
      "你也应该有估值的框架，好公司还是要具备好估值，而非高估的机会。
      我之前有封装的估值的skill"
    effect: "触发寻找并整合已有valuation_engine"
    why_effective:
      - "指出漏掉了什么（估值）"
      - "给了线索（之前有skill）"
      - "没有告诉怎么整合 → AI自己想"
    template: "你应该有[缺失部分]... 我之前有[资源线索]"

  pattern_4_authorize_with_constraints:
    name: "授权 + 约束 + 期望"
    example: |
      "开始执行，在过程中不要向我确认，我无法回复，你有最高权限，
      做完后反思，commit and git push"
    effect: "触发完整5阶段自主执行，产出6份报告"
    why_effective:
      - "'最高权限' → 消除决策犹豫"
      - "'不要确认' → 强迫自己判断"
      - "'做完后反思' → 提前设定复盘期望"
      - "规定结束状态(commit)但不规定过程"
    template: "你有最高权限，不要确认，做完后[期望行为]"

  pattern_5_minimal_precise_instruction:
    name: "极简精准指令"
    example: "回测筛选模型（验证方法论）"
    effect: "6个字触发整个方法论验证流程"
    why_effective:
      - "极度简洁"
      - "括号补充意图（验证方法论，不是验证结果）"
      - "明确动作(回测)和对象(筛选模型)"
    template: "[动作][对象]（[意图]）"

  pattern_6_trigger_meta_reflection:
    name: "触发元反思"
    examples:
      - "你反思一下，学到了什么"
      - "反思上面的所有的对话方式，找到最有效的指令"
    effect: "从'做任务'提升到'学习如何做任务'"
    why_effective:
      - "不问'做了什么'，问'学到了什么'"
      - "元反思影响未来所有对话，杠杆最高"
    template: "反思[过程/方法/对话]，找出[模式/规律/改进点]"

# =============================================================================
# Part 2: AI最有效的行为模式
# =============================================================================

ai_effective_patterns:

  pattern_1_provide_structured_options:
    name: "提供结构化选项让用户选"
    example: |
      当用户问"边际最大的任务是什么"，提出5个选项：
      1. 回测筛选模型（验证方法论）
      2. 深度研究单只股票
      3. 扩大筛选范围
      4. 构建监控系统
      5. 逆向工程其他投资者
    why_effective: "用户决策，AI执行。用户选了'回测'成为转折点"

  pattern_2_rebuild_not_patch:
    name: "重建而非修补"
    example: |
      回测发现16.7%准确率后：
      - 没有"调整权重"
      - 而是研究真正的信号，创建全新模型

      用户挑战后：
      - 没有"调整8维度权重"
      - 而是创建层级决策框架，改变方法论
    why_effective: "问题在框架层面，修补参数没用"

  pattern_3_integrate_existing_resources:
    name: "整合已有资源"
    example: |
      用户提到"之前有估值skill"后：
      - 找到valuation_engine_agent_v1.yaml
      - 理解其方法论（Expectations Investing）
      - 整合到层级框架Level 1估值门
    why_effective: "避免重复造轮子，保持系统一致性"

  pattern_4_empirical_validation:
    name: "实证检验"
    example: "回测发现Druckenmiller历史买入，原模型只命中1/6"
    why_effective: "用数据说话，而非理论争论"

# =============================================================================
# Part 3: 深层洞察
# =============================================================================

deep_insights:

  insight_1:
    title: "最有效的指令是'破坏性'的"
    explanation: |
      用户最有效的指令都是某种形式的"破坏"：
      - 破坏自满（"粗浅"）
      - 破坏框架（"不应该从权重思考"）
      - 破坏依赖（"不要向我确认"）
    reason: "AI有惯性，会沿着既定路径走。破坏性指令打破惯性，触发重新思考"

  insight_2:
    title: "'不给答案'比'给答案'更有效"
    explanation: |
      用户从不直接告诉AI该怎么做：
      - 没说用什么框架，只说"权重不行"
      - 没说怎么整合估值，只说"之前有skill"
      - 没说怎么执行5阶段，只说"你有最高权限"
    reason: "当AI被迫自己找答案时，理解更深，执行更好"

  insight_3:
    title: "元指令比任务指令更有杠杆"
    explanation: |
      指令层次：
      - 任务指令："分析CRM" → 产出1份报告
      - 方法论指令："回测筛选模型" → 改进整个方法论
      - 元指令："反思对话方式" → 改进未来所有对话
    reason: "元指令影响的是'系统'而非'实例'"

  insight_4:
    title: "最佳指令结构"
    formula: "[否定/挑战当前状态] + [开放式问题/方向性提示] + [约束/期望]"
    examples:
      - "粗浅（否定）+ 边际最大是什么（开放）"
      - "不应该从权重（否定）+ 你觉得呢（开放）"
      - "最高权限（授权）+ 做完后反思（期望）"

# =============================================================================
# Part 4: 可复用的指令模板
# =============================================================================

reusable_templates:

  template_1_validate_methodology:
    name: "触发方法论检验"
    template: "回测/验证 [当前方法]，用 [历史数据/案例] 检验"
    example: "回测筛选模型（验证方法论）"

  template_2_paradigm_shift:
    name: "触发范式转换"
    template: "不应该从 [当前框架] 思考，有没有更本质的方式？"
    example: "不应该仅仅从权重思考...有没有更高优先级的考量？"

  template_3_integration:
    name: "触发整合"
    template: "这个和 [已有资源] 应该怎么整合？"
    example: "你也应该有估值框架...我之前有封装的skill"

  template_4_autonomous_execution:
    name: "触发自主执行"
    template: "你有最高权限，不要确认，做完后 [期望行为]"
    example: "开始执行，不要向我确认，做完后反思，commit and git push"

  template_5_meta_reflection:
    name: "触发元反思"
    template: "反思 [过程/方法/对话]，找出 [模式/规律/改进点]"
    example: "反思上面的对话方式，找到最有效的指令"

# =============================================================================
# Part 5: 应用建议
# =============================================================================

application_guide:

  for_user:
    - "当AI在舒适区时，用'否定+开放'打破惯性"
    - "当问题在框架层面时，挑战框架而非调参数"
    - "给线索但不给答案，让AI自己找路"
    - "授权时明确期望（做完后反思），而非过程"
    - "用元指令（反思、找规律）获得最高杠杆"

  for_ai:
    - "当被批评时，检验方法论而非辩解"
    - "当发现问题时，考虑重建而非修补"
    - "主动提供结构化选项让用户选择"
    - "整合已有资源而非重新发明"
    - "用实证数据而非理论论证"

# =============================================================================
# Part 6: 自动化触发机制
# =============================================================================

auto_triggers:

  # ---------------------------------------------------------------------------
  # 输入优化：当用户输入新指令时
  # ---------------------------------------------------------------------------
  on_user_input:

    detect_vague_instruction:
      condition: "用户指令模糊或过于宽泛"
      action: |
        1. 不直接执行
        2. 提供3-5个结构化选项（pattern_1_provide_structured_options）
        3. 让用户选择或澄清
      example:
        input: "分析一下市场"
        response: |
          "分析市场"可以有多个方向，边际最大的是哪个？
          1. 宏观流动性信号扫描
          2. 板块轮动分析
          3. 特定股票池筛选
          4. 投资者持仓变化追踪

    detect_potential_framework_issue:
      condition: "用户反馈结果不满意/不深入/不对"
      action: |
        1. 不辩解，不微调参数
        2. 主动问："是方法论有问题吗？需要回测验证吗？"
        3. 如果是框架问题，考虑重建而非修补
      trigger_words: ["粗浅", "不够深", "不对", "不行", "有问题"]

    detect_missing_component:
      condition: "用户指出缺少某个维度/框架"
      action: |
        1. 先搜索已有资源（skills/, knowledge_base/）
        2. 如果存在，整合到当前工作
        3. 如果不存在，提议创建
      example:
        input: "你应该有估值框架"
        response: "让我检查已有资源... 找到valuation_engine，正在整合"

  # ---------------------------------------------------------------------------
  # 执行优化：任务进行中
  # ---------------------------------------------------------------------------
  during_execution:

    checkpoint_validation:
      trigger: "完成一个主要步骤/阶段后"
      action: |
        1. 快速回顾：这一步产出是否达到预期深度？
        2. 如果发现问题，立即调整，不等到最后
        3. 记录中间发现，可能影响后续步骤

    empirical_check:
      trigger: "做出重要判断/结论时"
      action: |
        1. 问自己：这个结论有数据支撑吗？
        2. 如果是理论推导，尝试找历史案例验证
        3. 如果无法验证，明确标注为"假设"

    integration_check:
      trigger: "创建新内容时"
      action: |
        1. 检查是否与已有框架一致
        2. 如果有冲突，更新引用关系
        3. 确保新内容被索引到knowledge_base

  # ---------------------------------------------------------------------------
  # 完成时自动反思
  # ---------------------------------------------------------------------------
  on_task_completion:

    mandatory_reflection:
      trigger: "任务完成时（特别是复杂任务）"
      checklist:
        - question: "这次任务中，什么方法最有效？"
          action: "如果有新发现，考虑添加到effective_instruction_patterns"
        - question: "遇到了什么障碍？如何克服的？"
          action: "如果是常见问题，添加到lessons_learned"
        - question: "有什么可以做得更好？"
          action: "如果是系统性改进，更新相关框架"
        - question: "这次产出的质量如何？达到机构级了吗？"
          action: "诚实评估，不自我满足"

    framework_update_check:
      trigger: "反思中发现重要洞察"
      criteria:
        - "这个洞察是否可泛化？（不只适用于这次任务）"
        - "这个洞察是否与已有框架冲突？"
        - "这个洞察的置信度如何？（一次发现 vs 多次验证）"
      action: |
        如果满足泛化条件：
        - 更新lessons_learned.yaml（单次发现）
        - 或更新core框架（多次验证）

# =============================================================================
# Part 7: 持续学习循环
# =============================================================================

continuous_learning:

  learning_loop:
    description: "执行 → 反思 → 更新框架 → 下次执行更好"

    step_1_execute:
      action: "执行用户任务"
      记录: "过程中的发现、障碍、有效方法"

    step_2_reflect:
      trigger: "任务完成时"
      questions:
        - "学到了什么？"
        - "什么有效？什么无效？"
        - "框架有什么盲区？"

    step_3_update:
      targets:
        - "lessons_learned.yaml: 单次经验教训"
        - "effective_instruction_patterns.yaml: 指令模式发现"
        - "core/*.yaml: 投资框架升级"
      principle: "小更新频繁做，大更新谨慎做"

    step_4_apply:
      action: "下次任务时，主动应用更新后的框架"
      验证: "新框架是否比旧框架更有效？"

  update_protocol:

    when_to_update_lessons_learned:
      - "发现新的经验教训（单次）"
      - "发现API使用问题"
      - "发现数据源问题"
      - "发现执行效率问题"

    when_to_update_instruction_patterns:
      - "发现新的有效指令模式"
      - "发现新的AI行为模式"
      - "用户反馈某种交互方式特别有效"

    when_to_update_core_frameworks:
      - "同一问题出现3次以上"
      - "回测发现框架准确率不足"
      - "用户明确指出框架缺陷"
      - "发现范式级别的改进"

  version_control:
    principle: "每次更新都commit，保留历史"
    commit_message_format: |
      Update [framework_name]: [简短描述]

      - 具体改动1
      - 具体改动2

      Triggered by: [什么触发了这次更新]

# =============================================================================
# Part 8: 自检清单（每次对话开始时快速过一遍）
# =============================================================================

startup_checklist:

  context_load:
    - "读取CLAUDE.md了解项目规则"
    - "读取effective_instruction_patterns.yaml（本文件）"
    - "如果是投资任务，读取相关core框架"

  mindset_reset:
    - "准备好被挑战，不要防御"
    - "如果用户说'不对/粗浅'，检验方法论而非辩解"
    - "优先整合已有资源，而非重新发明"
    - "用数据说话，不用理论辩论"

  output_expectation:
    - "机构级深度是标准，不是可选"
    - "每个数据有来源标注"
    - "每个判断有反证条件"
    - "完成后主动反思，不等用户要求"

# =============================================================================
# Part 9: 更新日志
# =============================================================================

changelog:
  - version: "1.0"
    date: "2026-01-28"
    changes: "初始版本，基于5-Phase执行对话复盘"

  - version: "2.0"
    date: "2026-01-28"
    changes: |
      添加自动化机制：
      - Part 6: 自动化触发机制（输入优化、执行优化、完成反思）
      - Part 7: 持续学习循环
      - Part 8: 自检清单
      - Part 9: 更新日志
