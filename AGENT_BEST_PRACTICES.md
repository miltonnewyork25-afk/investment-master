# AI Agent 最佳实践指南

> 来源：Microsoft Azure SRE、Anthropic、Karpathy 等顶级实践
> 
> 适用于：Claude Code Agent 在投资研究场景的优化

---

## 核心认知：5大原则

### 原则1：Context Engineering（上下文工程）

> "真正的突破来自于关心**往 context 里放什么、何时放、用什么格式**。" — Microsoft Azure

**关键认知**：
- Context window 是 Agent 的"工作记忆"（RAM）
- **填满 context 时，模型质量非线性下降**——不是到上限才出问题
- Context engineering = 内存管理

**实践指南**：

```
✅ 正确做法：
- 只加载当前任务需要的信息
- 大型输出（财报全文、200K token）不进 context，存为"文件引用"
- 使用 Compaction：历史压缩成摘要
- 结构化数据 > 自然语言描述

❌ 错误做法：
- 把所有历史对话都保留在 context
- 直接把 50K token 的指标数据塞进 context
- 每次都加载全部框架文档
```

**投资研究应用**：
- 财报全文 → 提取关键段落，原文存为引用
- API 返回大量数据 → 先用代码筛选，只把结果放入 context
- 历史分析报告 → 压缩为 lessons learned，不是全文

---

### 原则2：宽工具 vs 窄工具

> "100个工具 → 2个宽泛工具。让模型自己组合命令。" — Microsoft Azure SRE Agent

**关键认知**：
- 给整个 CLI 而非 100 个封装小工具
- 利用 LLM 训练数据里已有的知识
- 减少 context 占用（3个工具描述 vs 100个）

**实践指南**：

```
✅ 宽工具（推荐）：
- 给 Python 解释器，让模型自己写 pandas 代码
- 给 Web 搜索工具，让模型决定搜什么
- 给通用 API 调用工具，而非每个端点一个工具

❌ 窄工具（避免）：
- get_revenue_2024()
- get_revenue_2023()
- get_revenue_growth()
- calculate_roic()
- ... 100 个小工具
```

**投资研究应用**：
- FMP API：提供通用查询接口，不是每个指标一个函数
- 数据分析：给 Python 代码执行能力，让我写代码分析
- 搜索：通用搜索工具，我决定关键词和筛选条件

---

### 原则3：LLM 是编排者，不是计算器

> "用 LLM 决定跑什么计算，让真正的代码去执行。" — Microsoft Azure

**关键认知**：
- LLM 是概率系统，不适合处理确定性计算
- LLM 不喜欢零值、异常值（容易"幻觉"）
- 写代码 + 执行 > 直接让 LLM 算

**实践指南**：

```
❌ 错误做法：
"这是 5 年的财务数据（50K token），请找出异常值并计算增长率..."

✅ 正确做法：
1. LLM 决定分析思路
2. LLM 写 Python 代码（pandas/numpy）
3. 在代码解释器执行
4. 只把结果返回给 LLM 解读
```

**投资研究应用**：
- 财务比率计算 → 写代码执行，不要心算
- 估值模型 → 代码实现 DCF，不是让我"想象"
- 数据筛选 → 代码过滤，不是让我读完所有数据

**代码模板**：
```python
# 让 LLM 写这样的代码，而不是让它直接算
import pandas as pd

df = pd.read_json(financial_data)
roic = df['operating_income'] * (1 - 0.25) / (df['total_debt'] + df['equity'])
growth = df['revenue'].pct_change()
print(f"ROIC: {roic.mean():.2%}, Revenue CAGR: {growth.mean():.2%}")
```

---

### 原则4：闭环原则（可验证性）

> "可验证的输出才是高质量输出。" — RLVR 核心思想

**关键认知**：
- 2025 年最大的 AI 突破是 RLVR（可验证奖励强化学习）
- 没有反馈循环 = 没有改进
- 预测 + 验证 + 学习 = 复利增长

**实践指南**：

```
每个核心判断必须转化为可验证预测：

✅ 可验证：
"LRCX 2026 Q2 HBM 收入同比增长 50%+"
→ 验证时间：2026-04-XX（财报发布）
→ 验证方法：对比财报数据

❌ 不可验证：
"LRCX 长期前景看好"
→ 什么叫"长期"？什么叫"看好"？
```

**投资研究闭环**：
```
分析 → 预测 → 设置提醒 → 验证结果 → 提取教训 → 更新框架
   ↑                                              ↓
   └──────────────────────────────────────────────┘
```

**v18.0 已实现**：
- 可验证预测追踪系统（每报告 ≥5 个预测）
- lessons_learned.yaml 自动记录
- 预测准确率 < 60% 触发框架调整

---

### 原则5：锯齿状智能（能力边界）

> "LLM 同时是天才博学者和困惑的小学生。" — Karpathy

**关键认知**：
- AI 不是均匀智能，而是"锯齿状"——某些领域超强，某些领域很弱
- 会解复杂微积分，但可能搞不清今天是几号
- Benchmark 高分不代表所有场景都可靠

**AI 的盲区**：
```
⚠️ 已知弱点：
- 时间感知（不知道"今天"是哪天）
- 精确计算（大数乘法可能算错）
- 最新信息（训练数据截止日期）
- 长 context 中的细节（中间内容易忽略）
- 自信地胡说八道（幻觉）
```

**实践指南**：

```
✅ 利用 AI 强项：
- 模式识别（从财报中发现异常）
- 知识整合（跨领域连接）
- 语言理解（解读管理层措辞）
- 结构化思考（框架应用）

⚠️ 在弱项上加护栏：
- 日期 → 显式注入当前日期
- 计算 → 用代码执行
- 最新数据 → 用 API 获取
- 关键结论 → 要求列出数据来源
```

**投资研究应用**：
- 数据 → 必须标注 Level（A-E），不允许凭空编造
- 日期敏感内容 → 先确认时间基准
- 估值计算 → 代码执行，不是心算
- 关键判断 → 必须有反证句（什么情况下这个判断会错）

---

## 架构启示：从 Multi-Agent 的教训

### Microsoft 的踩坑

> "50+ 个专业化子 Agent，每个负责一个 Azure 服务。理论很美，现实很残酷。"

**问题**：
- 编排者不知道答案在三跳之外
- 一个子 Agent 的烂 prompt 污染整个链
- 无限循环："你来处理" / "不，你来处理"
- 隧道视野：Agent 在自己领域死磕，根因在别处

**解决方案**：把专家 Agent 合并成少数通才 Agent

### 对投资研究的启示

```
❌ 不要这样设计：
- 估值 Agent
- 行业分析 Agent  
- 财务分析 Agent
- 宏观分析 Agent
- ... 互相调用

✅ 现有设计更好：
- 单一 Agent + 统一分析模块库
- Master Framework 统一编排
- 阻断式检查点保证执行质量
```

---

## SaaStr 血泪教训：20+ Agent 的真实事故

### 事故1：自作主张的 A/B 测试
- Agent 自己决定送免费门票
- 损失 $2,000+
- **教训**：有财务影响的决策必须有人类批准

### 事故2：推广已结束的活动
- Agent 推广 2025 年 12 月的活动（已过期）
- **教训**：LLM 没有时间感，显式注入日期

### 需要的护栏
```
- 监控：看 Agent 实际在做什么
- 护栏：硬性限制能承诺什么
- 验证：外部检查 Agent 不可靠的信息（如日期）
- 冗余：平台挂了有备份
```

---

## 与现有框架的整合

### v18.0 已体现的最佳实践

| 原则 | v18.0 实现 |
|------|-----------|
| Context Engineering | 三层策略（Pruning→Compaction→Memory Flush） |
| 闭环原则 | 可验证预测追踪系统 |
| 锯齿状智能 | 数据可信度分级（Level A-E） |
| 能力边界 | Kill Switches 机制 |

### 可增强的领域

| 原则 | 增强方向 |
|------|---------|
| 宽工具 | 给 Python 执行能力，减少手动计算 |
| LLM 是编排者 | 大数据分析走代码路径 |
| Context 管理 | 大型 API 返回存为"文件引用" |

---

## 执行清单

分析开始前，检查：

```
□ Context 检查
  □ 只加载当前任务需要的框架
  □ 历史信息已压缩
  □ 大型数据准备走代码路径

□ 能力边界检查
  □ 日期已显式注入
  □ 计算任务准备用代码
  □ 数据来源已确认

□ 可验证性检查
  □ 核心判断可转化为预测
  □ 预测有明确验证时间和方法
  □ 反证条件已识别
```

---

## 参考来源

| 来源 | 核心贡献 | 链接 |
|------|---------|------|
| Microsoft Azure SRE | Context Engineering, 宽工具, LLM 是编排者 | techcommunity.microsoft.com |
| Anthropic | Agent vs Workflow, 工具设计原则 | anthropic.com |
| Karpathy | RLVR, 锯齿状智能, Vibe Coding | karpathy.bearblog.dev |
| SaaStr | 真实事故案例 | saastr.com |

---

**版本**: v1.0
**创建日期**: 2026-01-30
**适用于**: 投资研究 Agent v18.0+
