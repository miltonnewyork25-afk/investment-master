# 复利学习飞轮 v1.0

> 每次研究让下一次更好。不是线性积累，是指数提升。

---

## 1. 架构总览

### 三层架构

```
┌─────────────────────────────────────────────────┐
│  L1 主控层 (Main)                                │
│  框架管理 · 质量标准 · 知识银行 · 跨行业学习      │
│  docs/ · tests/ · CLAUDE.md · 实证数据库          │
└────────┬──────────┬──────────┬──────────┬────────┘
         │          │          │          │
    ┌────▼───┐ ┌────▼───┐ ┌───▼────┐ ┌───▼────┐
    │L2 金融 │ │L2 消费 │ │L2 半导 │ │L2 科技 │ ...
    │行业专规│ │行业专规│ │行业专规│ │行业专规│
    │报告执行│ │报告执行│ │报告执行│ │报告执行│
    └────┬───┘ └────┬───┘ └───┬────┘ └───┬────┘
         │          │         │          │
    ┌────▼───┐ ┌────▼───┐ ┌───▼────┐ ┌───▼────┐
    │L3 Agent│ │L3 Agent│ │L3 Agent│ │L3 Agent│
    │3-5/批次│ │3-5/批次│ │3-5/批次│ │3-5/批次│
    │Phase执行│ │Phase执行│ │Phase执行│ │Phase执行│
    └────────┘ └────────┘ └────────┘ └────────┘
```

### 当前信息流（单向，有缺陷）

```
Main ──push──> Worktree ──dispatch──> Agents ──write──> Reports ──[死路]
```

### 目标信息流（飞轮，复利）

```
Main ──push──> Worktree ──dispatch──> Agents ──write──> Reports
  ▲                                                        │
  │                                                        ▼
  │                                                  反思 (Post-Mortem)
  │                                                        │
  │                                                        ▼
  └────codify────  提炼通用教训  ◄────extract────  结构化Lessons
                        │
                        ▼
                  git merge → 所有Worktree
                        │
                        ▼
                  下一次研究更好 → 更好的Reports → 更好的反思 → ...
```

---

## 2. 飞轮的四个齿轮

### 齿轮1: 执行 (Execute)

在Worktree内按Phase 0-5执行Tier 3研究。这是产出。

**当前状态**: 稳定。7个项目验证了Phase结构。

### 齿轮2: 反思 (Reflect)

Complete报告质量门控通过后，**必须**执行结构化反思。

**当前状态**: 缺失。只有危机时才反思（META质量回退催生v24.0）。

### 齿轮3: 提炼 (Extract)

从反思中提取可泛化的教训，写入知识银行。

**当前状态**: 零散。教训散落在MEMORY.md和各种commit message中。

### 齿轮4: 传播 (Propagate)

通过git merge main将提炼的教训传播到所有Worktree。

**当前状态**: v25.0刚建立。之前各worktree v19-v24碎片化。

---

## 3. 实证数据库 — 7个项目的真实数据

### Agent架构实证对比

| 项目 | 行业 | 总Agents | 关键Phase配置 | 总产出 | vs目标 | 质量 |
|------|------|:-------:|-------------|:------:|:-----:|------|
| SOFI | 金融 | ~19 | P2:5, P3:5, P4:3, P5:3 | 271K | 175% | 908标注, 57%硬数据, 全CG通过 |
| META | 科技 | ~25 | P1:3, P2:4, P3:5, P4:4, P5:3 | 317K | 187% | 550+标注, 16KS, 22VP |
| GOOGL | 科技 | ~20 | 类似META | 311K | ~165% | SOTP-DCF偏差2.5% |
| COST | 消费 | ~27 | P0:7微型, P1-4分散 | 154K | ~130% | v21标准 |
| PG | 消费 | ~19 | P4: 4大型(M/N/O/P) | 205K | 216% | 731标注, 57%硬数据 |
| PLTR | 科技 | ~18 | P1:4, P2:4, P3:5 | 139K* | 117%* | 48.1密度, 75%硬数据 |
| TSM | 半导体 | ~8+线性 | P0:8专精 | 100K | ~130% | v20标准 |

*PLTR仅Phase 0-3.5

### 关键发现

**发现1: 最佳Agent团队规模 = 4-5/Phase**
- 5个Agent的Phase产出超目标50-80% (SOFI P2:180%, META P2:148%)
- 3个Agent的Phase产出刚好达标 (META P5:106%, SOFI P4:101%)
- 7个微型Agent不如4个中型Agent高效 (COST P0 vs PLTR P1)

**发现2: 最佳单Agent产出 = 10-15K字符**
- SOFI P2均值: 12.4K ← 最佳
- META P3均值: 13.4K ← 最佳
- PG P4均值: 12.2K ← 最佳
- COST微型Agent: 5.5K ← 太碎片化

**发现3: 产出从不低于目标**
- 最低: SOFI P1 (100%), 最高: PG P4 (327%)
- 均值: ~155%，说明目标设定偏保守

**发现4: 框架版本与质量正相关**
- v19-v20: 无标注密度/硬数据指标
- v21: 引入标注密度≥15/万
- v22+: 实际达到30-48/万 (2-3倍超标)

**发现5: 每个项目贡献了一个框架创新**
| 项目 | 贡献 | 框架版本 |
|------|------|---------|
| TSM | 预测市场PPDA/PMSI | v10.0 |
| COST | 微型Agent模式+MTC协议 | v19-v21 |
| GOOGL | 反幻觉协议+DM锚点 | v22.0 |
| META | 铁律F质量不回退+CG门控 | v24.0 |
| SOFI | Checkpoint协议+Agent返回压缩 | v25.0 |
| PG | Phase 4看空强化(4大型Agent) | v22.0 |
| PLTR | (进行中) | v25.0+ |

**这就是复利**: 每个项目不仅产出报告，还产出了让下一个项目更好的框架改进。问题是这个过程一直是被动的(出问题才改)，不是主动的(完成后反思)。

---

## 4. 结构化反思协议 (Post-Mortem)

### 触发时机
- Complete报告通过CG门控后，**同一会话内**执行
- 如果context不足，作为下一会话的**第一个任务**

### 反思模板

在 `reports/{TICKER}/data/` 中写入 `reflection.md`:

```markdown
# {TICKER} 研究反思 — {日期}

## 1. 数字摘要
- 总字符: {X}K (目标{Y}K的{Z}%)
- 总Agents: {N}个, 分{M}批
- 最佳Phase: {Phase X} — 因为{原因}
- 最差Phase: {Phase Y} — 因为{原因}
- 框架版本: v{A.B}

## 2. 什么工作得好？(保持)
- {具体做法} → {量化效果}

## 3. 什么工作得不好？(改进)
- {具体问题} → {根因} → {建议改进}

## 4. 发现了什么新模式？(提炼)
- {模式描述} → {适用范围} → {建议编码到哪个docs/文件}

## 5. Agent架构评估
| Phase | Agent数 | 产出/Agent | 评价 | 下次建议 |
|-------|---------|-----------|------|---------|

## 6. 对其他行业的启示
- {insight} → 适用于{行业/worktree}

## 7. 框架改进提案 (如有)
- 提案: {描述}
- 影响文件: {docs/xxx.md}
- 优先级: {高/中/低}
```

### 反思后动作

1. `reflection.md` 提交到当前worktree
2. 如果有框架改进提案 → 切换到main → 更新对应docs/ → commit
3. 运行 `bash tests/framework_health_check.sh` 确认传播准备
4. `git merge main` 到所有活跃worktree
5. 更新本文件的"实证数据库"章节

---

## 5. 主控-蜂群关系设计

### 主控(Main)的职责 — 不是指挥官，是知识银行

| 职责 | 具体内容 | 不做的事 |
|------|---------|---------|
| 知识保管 | 维护docs/中的所有框架文档 | 不直接执行研究 |
| 质量标准 | 定义CG门控标准、Fast Gate | 不在运行中干预Agent |
| 跨行业学习 | 汇总各worktree的reflection | 不强制统一Agent架构 |
| 工具维护 | tests/脚本、.claude/skills/ | 不规定Agent数量 |
| 健康监控 | framework_health_check.sh | 不自动修复(提醒人) |

### 蜂群(Worktree)的自主权

| 自主权 | 说明 |
|--------|------|
| Agent数量 | 根据模块复杂度自行决定(参考指导原则) |
| Agent命名 | 自由(Greek字母/功能名/编号) |
| 执行节奏 | 3+2还是4+1由context状态决定 |
| 行业专规 | thin-shell CLAUDE.md中的行业部分自行维护 |
| 本地优化 | 可在worktree内实验新做法 |

### 蜂群向主控的反馈义务

| 义务 | 时机 | 格式 |
|------|------|------|
| reflection.md | Complete报告通过后 | 上述模板 |
| 框架改进提案 | 发现可泛化的新做法时 | reflection.md第7节 |
| 实证数据 | 每Phase完成 | STATUS.md自动记录 |
| 失败报告 | Agent失败/质量不达标时 | agent_logs/ |

---

## 6. Worktree内部架构 — Agent团队设计原则

### 从实证数据提炼的5条原则 (已编码到 `docs/parallel_execution.md` v6.0)

1. **模块驱动Agent数量**: 按模块数和复杂度，不是固定数字
2. **按类型设产出目标**: 数据密集12-20K / 分析判断10-15K / 输出型5-8K
3. **Context感知动态调整**: 前期4-5 Agent / 后期2-3 Agent
4. **看空Agent必须独立**: 不读前序看多结论
5. **Checkpoint必写**: 每批次完成后

### Agent团队设计参考表 (基于7个项目实证)

| Phase | 推荐Agent数 | 推荐产出/Agent | 实证依据 |
|:---:|:---:|:---:|---------|
| 0 | 3-5 专精 | 数据文件 | SOFI/META/PLTR |
| 0.5 | 3-5 规划 | 10-20K | META α1-α5 |
| 1 | 3-4 | 10-13K | META δ1-3, PLTR α-δ |
| 2 | 4-5 | 11-15K | SOFI 5A(180%), META 4A(148%) |
| 3+3.5 | 4-5 | 12-17K | META ζ1-5, PLTR 5A |
| 4 | 3-4 | 12-22K | PG M/N/O/P, META η1-4 |
| 5 | 3 | 10-12K | META θ1-3, SOFI 3A |

### Agent间协作模式

```
模式A: 独立并行 (默认)
Agent_1 ──→ staging_1.md
Agent_2 ──→ staging_2.md    共享: shared_context.md (只读)
Agent_3 ──→ staging_3.md
主线程 ◄── 汇总合并

模式B: 接力式 (罕见，仅Phase 0数据链)
Agent_1 ──→ raw_data ──→ Agent_2 ──→ structured_data ──→ Agent_3

模式C: 对抗式 (Phase 4专用)
Agent_看多 ──→ 看多论证
Agent_看空 ──→ 独立看空 (不读看多)    ← 铁律: 信息隔离
主线程 ◄── 综合裁决
```

---

## 7. 飞轮运行协议 — 定期触发

### 触发条件

| 触发 | 动作 |
|------|------|
| Complete报告通过CG | 执行反思 → 写reflection.md → 提取教训 |
| 累计完成3个新项目 | 更新本文件的实证数据库 + 重新审视原则 |
| 框架版本跳号(vN→vN+1) | 检查所有worktree同步状态 |
| 会话启动(铁律D步骤3) | 运行健康检查 |
| 用户明确要求 | 全面反思 + 架构审视 |

### 飞轮执行检查清单

```
□ 读取最近3个项目的reflection.md
□ 对比实证数据库的趋势(是否在改善)
□ 识别跨项目的重复问题
□ 提出≤3个改进提案
□ 更新本文件
□ 如有框架修改 → commit main → merge到活跃worktree
□ 运行 bash tests/framework_health_check.sh 确认健康
```

### 复利量化指标

跟踪以下指标的项目间趋势：

| 指标 | 方向 | 说明 |
|------|------|------|
| 标注密度(/万字符) | ↑ | v21: 15目标 → v25实际: 30-48 |
| 硬数据占比 | ↑ | v21: 40%目标 → v25实际: 57-75% |
| 产出/Agent(K字符) | 稳定 | 10-15K是甜点区 |
| 产出vs目标(%) | 稳定偏↓ | 155%均值说明目标可上调 |
| Agent失败率 | ↓ | <1%，已接近零 |
| Context耗尽次数/项目 | ↓ | v25前约3-5次 → v25目标≤2次 |
| 框架更新间隔(项目数) | 从1→3+ | 目标: 不再每个项目都改框架 |

---

## 8. 跨Worktree知识传递路径

### 已验证的跨行业适用模式

| 模式 | 来源项目 | 已扩展到 | 效果 |
|------|---------|---------|------|
| DM锚点系统 | GOOGL | SOFI, META, PLTR | 消除跨Phase数据不一致 |
| Checkpoint.yaml | SOFI | META, PLTR | 1句话恢复 vs 500字prompt |
| CG门控11项 | META | 所有(v24.0) | 防质量回退 |
| Agent返回压缩 | v23.0设计 | PLTR首用 | 94%context节省 |
| 看空Agent隔离 | PG Phase 4 | 所有(v22.0) | 更强的对抗审查 |

### 潜在但未传播的模式

| 模式 | 来源 | 为何未传播 | 适用行业 |
|------|------|-----------|---------|
| MTC协议(微型Agent) | COST | 未反思提炼 | 数据密集型Phase 0 |
| Greek字母命名 | META | 仅在生态科技 | 所有(命名标准化) |
| PPDA背离分析 | TSM | 仅在半导体 | 所有有预测市场数据的 |
| 信用风暴矩阵 | SOFI | 仅在金融 | 有信贷敞口的 |

**这就是飞轮要解决的**: 上面4个模式如果更早传播，后续项目就能直接受益。

---

## 9. 下一次迭代目标

### PLTR完成后的反思重点
1. Phase 0.5的5-agent规划模式效果如何？
2. v25.0 checkpoint在context管理上是否真的减少了耗尽次数？
3. PLTR是生态科技行业，但更像科技平台 — 行业分类是否需要调整？

### 框架稳定性目标
- v25.0应能支撑≥3个项目不需要大版本升级
- 小版本(v25.1, v25.2)通过反思驱动，不通过危机驱动
- 实证数据库每3个项目更新一次

---

*本文件本身也是飞轮的一部分 — 每次反思后更新。*
